{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676d1647-c15e-4398-a211-60ef7b52ea50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Extraction & Scraping\n",
    "\n",
    "This project aims to construct a comprehensive, \"ready-to-use\" dataset of European football matches enriched with geospatial data. By combining match schedules with precise stadium coordinates, we enable location-based analytics (e.g., finding accommodation near a specific match).\n",
    "\n",
    "The project follows a robust **ETL (Extract, Transform, Load)** architecture:\n",
    "\n",
    "- **Extract**: We ingest raw data from web scraping (Wikipedia) and open data repositories (CSV files).\n",
    "- **Transform**: We clean, normalize, and map disparate data sources to a common schema.\n",
    "- **Load**: We enrich the data and store it in a unified table for downstream usage.\n",
    "\n",
    "#### Infrastructure & Proxy Configuration\n",
    "\n",
    "To perform web scraping at scale without triggering anti-bot mechanisms or IP bans, we utilize the **Bright Data** proxy network. This allows us to route our requests through legitimate IP addresses.\n",
    "\n",
    "We configure our connection using the **Native access via proxy user name and password** method. We control the proxy behavior dynamically by modifying the username string in our code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "247ae340-e5b3-4fb0-a695-dadaf6cfada6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDCCD A. Stadium Geolocation (Web Scraping)\n",
    "- **Source**: Wikipedia (16 European Domestic Leagues).\n",
    "- **Goal**: To acquire precise GPS coordinates (Latitude & Longitude) for over 150 European stadiums.\n",
    "- **Method**: We utilize `BeautifulSoup` to navigate Wikipedia's HTML structure, extracting hidden geographical tags. The pipeline includes a **Dynamic Column Detection** system to automatically identify data columns (e.g., *Team* vs *Stadium*) by analyzing headers and keyword density where fixed indexing would fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c74b094e-529f-4038-8142-a587e846404a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Premier League...\n   -> Success. Found 20 teams. (20 with coords)\nScraping: La Liga...\n   -> Success. Found 20 teams. (20 with coords)\nScraping: Bundesliga...\n   -> Success. Found 18 teams. (18 with coords)\nScraping: Serie A...\n   -> Success. Found 20 teams. (20 with coords)\nScraping: Ligue 1...\n   -> Success. Found 18 teams. (18 with coords)\nScraping: Primeira Liga...\n   -> Success. Found 18 teams. (18 with coords)\nScraping: Eredivisie...\n   -> Success. Found 18 teams. (18 with coords)\nScraping: Belgian Pro League...\n   -> Success. Found 16 teams. (16 with coords)\nScraping: Süper Lig...\n   -> Success. Found 19 teams. (17 with coords)\nScraping: Super League Greece...\n   -> Success. Found 14 teams. (14 with coords)\nScraping: Austrian Bundesliga...\n   -> Success. Found 12 teams. (12 with coords)\nScraping: Czech First League...\n   -> Success. Found 16 teams. (16 with coords)\nScraping: Danish Superliga...\n   -> Success. Found 12 teams. (12 with coords)\nScraping: Polish Ekstraklasa...\n   -> Success. Found 18 teams. (18 with coords)\nScraping: Ukrainian Premier League...\n   -> Success. Found 29 teams. (27 with coords)\nScraping: Croatian Football League...\n   -> Success. Found 10 teams. (10 with coords)\n\n========================================\nFinal Count: 274 stadiums ready.\n========================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import urllib3\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "# ==========================================\n",
    "# 0. SETUP & CONFIGURATION\n",
    "# ==========================================\n",
    "# Suppress SSL warnings to keep output clean\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Proxy Configuration (User Provided)\n",
    "PASSWORD = os.getenv('BRIGHTDATA_PASSWORD', 'YOUR_PASSWORD_HERE')\n",
    "BASE_USERNAME = os.getenv('BRIGHTDATA_USER', 'YOUR_ZONE_USERNAME_HERE') \n",
    "HOST = 'brd.superproxy.io'\n",
    "PORT = '33335'\n",
    "country_code = \"hu\" \n",
    "session_id = random.randint(1, 1000000)\n",
    "FINAL_USERNAME = f\"{BASE_USERNAME}-country-{country_code}-session-{session_id}\"\n",
    "\n",
    "PROXIES = {\n",
    "    'http': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}', \n",
    "    'https': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}'\n",
    "}\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Supported Wiki languages for fallback coordinate search\n",
    "WIKI_LANGUAGES = ['en', 'de', 'fr', 'es', 'it', 'pt', 'nl', 'tr', 'pl', 'el', 'cs', 'da', 'hr', 'uk']\n",
    "\n",
    "# ==========================================\n",
    "# 1. ROBUST HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def safe_int(val, default=1):\n",
    "    \"\"\"Safely converts a value to int. Returns default if None or invalid.\"\"\"\n",
    "    if val is None:\n",
    "        return default\n",
    "    try:\n",
    "        # Handles strings like \"2\", \"2.0\", or integers\n",
    "        return int(float(val))\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "def dms_to_decimal(dms_str):\n",
    "    \"\"\"Converts Degrees-Minutes-Seconds string to decimal latitude/longitude.\"\"\"\n",
    "    try:\n",
    "        if not dms_str: return None\n",
    "        dms_str = dms_str.strip().upper()\n",
    "        # Split by degree/minute/second symbols\n",
    "        parts = re.split(r'[°′\\'″\"]+', dms_str)\n",
    "        if len(parts) < 3: return None\n",
    "        \n",
    "        deg = float(parts[0])\n",
    "        mn = float(parts[1]) if parts[1] else 0.0\n",
    "        # Handle seconds and direction\n",
    "        sec = 0.0\n",
    "        direction = 'N'\n",
    "        \n",
    "        # Logic to find seconds and direction (N/S/E/W)\n",
    "        if len(parts) > 2 and parts[2]:\n",
    "            if parts[2] in ['N','S','E','W']:\n",
    "                direction = parts[2]\n",
    "            else:\n",
    "                sec = float(parts[2])\n",
    "                if len(parts) > 3 and parts[3] in ['N','S','E','W']:\n",
    "                    direction = parts[3]\n",
    "        \n",
    "        # Check last character of original string for direction if not found yet\n",
    "        if direction == 'N' and dms_str[-1] in ['N','S','E','W']:\n",
    "            direction = dms_str[-1]\n",
    "\n",
    "        val = deg + (mn / 60.0) + (sec / 3600.0)\n",
    "        return -val if direction in ['S', 'W'] else val\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "def get_interlanguage_links(url):\n",
    "    \"\"\"Finds links to the same Wikipedia article in other languages.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, proxies=PROXIES, headers=HEADERS, verify=False, timeout=10)\n",
    "        if r.status_code != 200: return {}\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        lang_links = {}\n",
    "        for link in soup.find_all('a', class_='interlanguage-link-target'):\n",
    "            href = link.get('href', '')\n",
    "            match = re.search(r'https://(\\w+)\\.wikipedia\\.org', href)\n",
    "            if match:\n",
    "                lang_links[match.group(1)] = href\n",
    "        return lang_links\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def try_coords_from_url(url):\n",
    "    \"\"\"Attempts to extract coordinates from a single Wikipedia URL.\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, proxies=PROXIES, headers=HEADERS, verify=False, timeout=10)\n",
    "        if r.status_code != 200: return None, None\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        # Method 1: Standard Geo tag (decimal)\n",
    "        geo = soup.find('span', class_='geo')\n",
    "        if geo:\n",
    "            try:\n",
    "                parts = geo.text.split(';')\n",
    "                return float(parts[0]), float(parts[1])\n",
    "            except: pass\n",
    "            \n",
    "        # Method 2: Latitude/Longitude spans (DMS)\n",
    "        lat_elem = soup.find('span', class_='latitude')\n",
    "        lon_elem = soup.find('span', class_='longitude')\n",
    "        if lat_elem and lon_elem:\n",
    "            return dms_to_decimal(lat_elem.text), dms_to_decimal(lon_elem.text)\n",
    "    except:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def get_coords(url):\n",
    "    \"\"\"\n",
    "    Main coordinate fetcher. \n",
    "    1. Tries the English page.\n",
    "    2. If missing, tries other language versions (German, French, etc.) of the same page.\n",
    "    \"\"\"\n",
    "    if not url or \"redlink=1\" in url: return None, None\n",
    "    if url.startswith('/'): url = f\"https://en.wikipedia.org{url}\"\n",
    "    \n",
    "    # Try 1: Direct URL\n",
    "    lat, lon = try_coords_from_url(url)\n",
    "    if lat: return lat, lon\n",
    "    \n",
    "    # Try 2: Interlanguage links\n",
    "    lang_links = get_interlanguage_links(url)\n",
    "    for lang in WIKI_LANGUAGES:\n",
    "        if lang == 'en': continue\n",
    "        \n",
    "        alt_url = lang_links.get(lang)\n",
    "        if not alt_url:\n",
    "            # Construct guessed URL if link not found\n",
    "            title = url.split('/wiki/')[-1]\n",
    "            alt_url = f\"https://{lang}.wikipedia.org/wiki/{title}\"\n",
    "        \n",
    "        lat, lon = try_coords_from_url(alt_url)\n",
    "        if lat: return lat, lon\n",
    "        time.sleep(0.5) # Be polite\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def parse_html_table_to_matrix(table):\n",
    "    \"\"\"\n",
    "    Parses an HTML table into a 2D list (matrix), handling rowspans and colspans.\n",
    "    Uses safe_int() to prevent TypeErrors.\n",
    "    \"\"\"\n",
    "    rows = table.find_all('tr')\n",
    "    # Initialize a large empty grid\n",
    "    matrix = []\n",
    "    for _ in rows: matrix.append([None] * 50) \n",
    "    \n",
    "    for r_idx, row in enumerate(rows):\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        c_idx = 0\n",
    "        for cell in cells:\n",
    "            # Skip cells that are already filled by a previous rowspan\n",
    "            while matrix[r_idx][c_idx] is not None: \n",
    "                c_idx += 1\n",
    "            \n",
    "            # Extract text and link\n",
    "            text = cell.get_text(strip=True).split('\\n')[0]\n",
    "            link_tag = cell.find('a')\n",
    "            link = link_tag.get('href') if link_tag else None\n",
    "            \n",
    "            cell_data = {'text': text, 'link': link}\n",
    "            \n",
    "            # --- FIXED LOGIC HERE ---\n",
    "            # Safely get rowspan and colspan\n",
    "            rs = safe_int(cell.get('rowspan'), default=1)\n",
    "            cs = safe_int(cell.get('colspan'), default=1)\n",
    "            \n",
    "            # Fill the matrix\n",
    "            for r in range(rs):\n",
    "                for c in range(cs):\n",
    "                    if r_idx + r < len(matrix):\n",
    "                        matrix[r_idx + r][c_idx + c] = cell_data\n",
    "            \n",
    "            c_idx += cs\n",
    "            \n",
    "    # Remove empty trailing columns/rows\n",
    "    return [row for row in matrix if any(c is not None for c in row)]\n",
    "\n",
    "def find_columns(matrix):\n",
    "    \"\"\"Identifies the index of the 'Team' and 'Stadium' columns.\"\"\"\n",
    "    if not matrix or len(matrix) < 2: return -1, -1\n",
    "    \n",
    "    headers = [c['text'].lower() if c else '' for c in matrix[0]]\n",
    "    t_idx, s_idx = -1, -1\n",
    "    \n",
    "    # 1. Try finding specific Headers\n",
    "    for i, h in enumerate(headers):\n",
    "        if any(x in h for x in ['team', 'club']): t_idx = i\n",
    "        if any(x in h for x in ['stadium', 'venue', 'ground', 'arena']): s_idx = i\n",
    "        \n",
    "    if t_idx != -1 and s_idx != -1 and t_idx != s_idx:\n",
    "        return t_idx, s_idx\n",
    "\n",
    "    # 2. Fallback: Scan column content for keywords\n",
    "    stadium_keywords = ['stadium', 'arena', 'park', 'field', 'ground', 'stadion']\n",
    "    max_cols = max(len(r) for r in matrix)\n",
    "    s_scores = [0] * max_cols\n",
    "    \n",
    "    for c in range(max_cols):\n",
    "        col_texts = [r[c]['text'].lower() for r in matrix[1:] if c < len(r) and r[c]]\n",
    "        s_scores[c] = sum(1 for t in col_texts if any(k in t for k in stadium_keywords))\n",
    "    \n",
    "    if max(s_scores) > 0:\n",
    "        s_idx = s_scores.index(max(s_scores))\n",
    "        \n",
    "    # Heuristic: If we found stadium, Team is usually col 0 or 1\n",
    "    if s_idx != -1:\n",
    "        if s_idx == 0: t_idx = 1\n",
    "        else: t_idx = 0\n",
    "        \n",
    "    return t_idx, s_idx\n",
    "\n",
    "# ==========================================\n",
    "# 2. MAIN LOGIC\n",
    "# ==========================================\n",
    "def scrape_league(league_name, country_code, url):\n",
    "    print(f\"Scraping: {league_name}...\")\n",
    "    data = []\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, proxies=PROXIES, headers=HEADERS, verify=False, timeout=20)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        tables = soup.find_all('table', class_=['wikitable', 'article-table'])\n",
    "        \n",
    "        for table in tables:\n",
    "            matrix = parse_html_table_to_matrix(table)\n",
    "            t_idx, s_idx = find_columns(matrix)\n",
    "            \n",
    "            if t_idx == -1 or s_idx == -1: continue\n",
    "            \n",
    "            table_data = []\n",
    "            valid_table = True\n",
    "            \n",
    "            for row in matrix[1:]:\n",
    "                # Ensure row has enough columns\n",
    "                if len(row) <= max(t_idx, s_idx): continue\n",
    "                \n",
    "                t_cell = row[t_idx]\n",
    "                s_cell = row[s_idx]\n",
    "                \n",
    "                if not t_cell or not s_cell: continue\n",
    "                \n",
    "                t_text = t_cell['text']\n",
    "                s_text = s_cell['text']\n",
    "                \n",
    "                # Validation: Skip \"Capacity\" or \"Location\" rows that look like headers\n",
    "                if len(t_text) < 2 or len(s_text) < 3: continue\n",
    "                if any(x in t_text.lower() for x in ['stadium', 'capacity', 'location']):\n",
    "                    valid_table = False\n",
    "                    break\n",
    "                    \n",
    "                # Get Coordinates\n",
    "                lat, lon = get_coords(s_cell['link'])\n",
    "                \n",
    "                table_data.append({\n",
    "                    \"League\": league_name,\n",
    "                    \"Country\": country_code,\n",
    "                    \"Team\": t_text,\n",
    "                    \"Stadium\": s_text,\n",
    "                    \"Latitude\": lat,\n",
    "                    \"Longitude\": lon\n",
    "                })\n",
    "            \n",
    "            # If table yielded good data, we are done with this league\n",
    "            if valid_table and len(table_data) >= 4:\n",
    "                data.extend(table_data)\n",
    "                found = sum(1 for d in table_data if d['Latitude'])\n",
    "                print(f\"   -> Success. Found {len(table_data)} teams. ({found} with coords)\")\n",
    "                break\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   -> Error: {e}\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION\n",
    "# ==========================================\n",
    "leagues = [\n",
    "    (\"Premier League\", \"England\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Premier_League\"),\n",
    "    (\"La Liga\", \"Spain\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_La_Liga\"),\n",
    "    (\"Bundesliga\", \"Germany\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Bundesliga\"),\n",
    "    (\"Serie A\", \"Italy\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Serie_A\"),\n",
    "    (\"Ligue 1\", \"France\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Ligue_1\"),\n",
    "    (\"Primeira Liga\", \"Portugal\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Primeira_Liga\"),\n",
    "    (\"Eredivisie\", \"Netherlands\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Eredivisie\"),\n",
    "    (\"Belgian Pro League\", \"Belgium\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Belgian_Pro_League\"),\n",
    "    (\"Süper Lig\", \"Turkey\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_S%C3%BCper_Lig\"),\n",
    "    (\"Super League Greece\", \"Greece\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Super_League_Greece\"),\n",
    "    (\"Austrian Bundesliga\", \"Austria\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Austrian_Football_Bundesliga\"),\n",
    "    (\"Czech First League\", \"Czech Republic\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Czech_First_League\"),\n",
    "    (\"Danish Superliga\", \"Denmark\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Danish_Superliga\"),\n",
    "    (\"Polish Ekstraklasa\", \"Poland\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Ekstraklasa\"),\n",
    "    (\"Ukrainian Premier League\", \"Ukraine\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Ukrainian_Premier_League\"),\n",
    "    (\"Croatian Football League\", \"Croatia\", \"https://en.wikipedia.org/wiki/2024%E2%80%9325_Croatian_Football_League\")\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "for l in leagues:\n",
    "    all_data.extend(scrape_league(*l))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Filter out rows where \"Team\" is accidentally a header\n",
    "if not df.empty:\n",
    "    df = df[~df['Team'].str.contains(\"Stadium|Capacity\", case=False, na=False)]\n",
    "\n",
    "# Create the final clean dataset (Only rows with valid Lat/Lon)\n",
    "df_stadiums = df.dropna(subset=['Latitude', 'Longitude']).copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Final Count: {len(df_stadiums)} stadiums ready.\")\n",
    "print(\"=\"*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc822ac-bb64-44ad-bca8-6164a91c2d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>League</th><th>Country</th><th>Team</th><th>Stadium</th><th>Latitude</th><th>Longitude</th></tr></thead><tbody><tr><td>Premier League</td><td>England</td><td>Arsenal</td><td>Emirates Stadium</td><td>51.55667</td><td>-0.10611</td></tr><tr><td>Premier League</td><td>England</td><td>Aston Villa</td><td>Villa Park</td><td>52.509166666667</td><td>-1.8847222222222</td></tr><tr><td>Premier League</td><td>England</td><td>Bournemouth</td><td>Dean Court</td><td>50.73528</td><td>-1.83833</td></tr><tr><td>Premier League</td><td>England</td><td>Brentford</td><td>Brentford Community Stadium</td><td>51.49083</td><td>-0.28861</td></tr><tr><td>Premier League</td><td>England</td><td>Brighton & Hove Albion</td><td>Falmer Stadium</td><td>50.861822222222</td><td>-0.083277777777778</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Premier League",
         "England",
         "Arsenal",
         "Emirates Stadium",
         51.55667,
         -0.10611
        ],
        [
         "Premier League",
         "England",
         "Aston Villa",
         "Villa Park",
         52.509166666667,
         -1.8847222222222
        ],
        [
         "Premier League",
         "England",
         "Bournemouth",
         "Dean Court",
         50.73528,
         -1.83833
        ],
        [
         "Premier League",
         "England",
         "Brentford",
         "Brentford Community Stadium",
         51.49083,
         -0.28861
        ],
        [
         "Premier League",
         "England",
         "Brighton & Hove Albion",
         "Falmer Stadium",
         50.861822222222,
         -0.083277777777778
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "League",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Team",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Stadium",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Longitude",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_stadiums.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8364d9f-e525-4aca-a173-14f3653d6114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDCCDB.  Stadium URL Discovery (Web Scraping)\n",
    "- **Source**: StadiumGuide.com (17 Major European Nations).\n",
    "- **Goal**: To build a comprehensive index of valid stadium profile URLs for every major European football nation, serving as the foundation for the geolocation features.\n",
    "- **Method**: We utilize requests with resilient proxy rotation (BrightData) to bypass anti-bot measures. The pipeline employs a \"Country-First\" strategy, crawling national overview pages rather than league tables to capture a static, complete list of stadiums. It applies robust filtering logic to strip out navigation links (e.g., \"tickets\", \"about\") and duplicates, ensuring only valid stadium profile links are retained for the final scraping phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c14a4451-a081-4c2e-87c0-410172763840",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Country: England...\n  -> Found 66 stadiums in England.\nScraping Country: Spain...\n  -> Found 48 stadiums in Spain.\nScraping Country: Germany...\n  -> Found 43 stadiums in Germany.\nScraping Country: Italy...\n  -> Found 37 stadiums in Italy.\nScraping Country: France...\n  -> Found 42 stadiums in France.\nScraping Country: Portugal...\n  -> Found 15 stadiums in Portugal.\nScraping Country: Netherlands...\n  -> Found 25 stadiums in Netherlands.\nScraping Country: Belgium...\n  -> Found 16 stadiums in Belgium.\nScraping Country: Turkey...\n  -> Found 14 stadiums in Turkey.\nScraping Country: Greece...\n  -> Found 8 stadiums in Greece.\nScraping Country: Denmark...\n  -> Found 9 stadiums in Denmark.\nScraping Country: Austria...\n  -> Found 12 stadiums in Austria.\nScraping Country: Poland...\n  -> Found 20 stadiums in Poland.\nScraping Country: Ukraine...\n  -> Found 10 stadiums in Ukraine.\nScraping Country: Croatia...\n  -> Found 6 stadiums in Croatia.\nScraping Country: Russia...\n  -> Found 22 stadiums in Russia.\nScraping Country: Scotland...\n  -> Found 16 stadiums in Scotland.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import urllib3\n",
    "import warnings\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION & PROXIES\n",
    "# ==========================================\n",
    "\n",
    "# Suppress SSL warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "PASSWORD = os.getenv('BRIGHTDATA_PASSWORD', 'YOUR_PASSWORD_HERE')\n",
    "BASE_USERNAME = os.getenv('BRIGHTDATA_USER', 'YOUR_ZONE_USERNAME_HERE') \n",
    "HOST = 'brd.superproxy.io'\n",
    "PORT = '33335'\n",
    "country_code = \"hu\" \n",
    "session_id = random.randint(1, 1000000)\n",
    "FINAL_USERNAME = f\"{BASE_USERNAME}-country-{country_code}-session-{session_id}\"\n",
    "\n",
    "PROXIES = {\n",
    "    'http': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}', \n",
    "    'https': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}'\n",
    "}\n",
    "\n",
    "# --- NEW: COUNTRY MAP ---\n",
    "# We point to the main country index pages which are more reliable than league pages.\n",
    "COUNTRY_MAP = [\n",
    "    (\"England\", \"https://www.stadiumguide.com/england/\"),\n",
    "    (\"Spain\", \"https://www.stadiumguide.com/spain/\"),\n",
    "    (\"Germany\", \"https://www.stadiumguide.com/germany/\"),\n",
    "    (\"Italy\", \"https://www.stadiumguide.com/italy/\"),\n",
    "    (\"France\", \"https://www.stadiumguide.com/france/\"),\n",
    "    (\"Portugal\", \"https://www.stadiumguide.com/portugal/\"),\n",
    "    (\"Netherlands\", \"https://www.stadiumguide.com/netherlands/\"),\n",
    "    (\"Belgium\", \"https://www.stadiumguide.com/belgium/\"),\n",
    "    (\"Turkey\", \"https://www.stadiumguide.com/turkey/\"),\n",
    "    (\"Greece\", \"https://www.stadiumguide.com/greece/\"),\n",
    "    (\"Denmark\", \"https://www.stadiumguide.com/denmark/\"),\n",
    "    (\"Austria\", \"https://www.stadiumguide.com/austria/\"),\n",
    "    (\"Poland\", \"https://www.stadiumguide.com/poland/\"),\n",
    "    (\"Ukraine\", \"https://www.stadiumguide.com/ukraine/\"),\n",
    "    (\"Croatia\", \"https://www.stadiumguide.com/croatia/\"),\n",
    "    (\"Russia\", \"https://www.stadiumguide.com/russia/\"),\n",
    "    (\"Scotland\", \"https://www.stadiumguide.com/scotland/\")\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# 2. ROBUST SCRAPER FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def get_soup_with_retry(url, retries=3):\n",
    "    \"\"\"Tries to fetch the URL multiple times.\"\"\"\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, proxies=PROXIES, headers=HEADERS, verify=False, timeout=20)\n",
    "            if r.status_code == 200:\n",
    "                return BeautifulSoup(r.content, 'html.parser')\n",
    "            elif r.status_code == 404:\n",
    "                print(f\"  [!] 404 Not Found: {url}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"  [~] Retry {i+1}/{retries} for {url} ({str(e)[:50]}...)\")\n",
    "            time.sleep(2)\n",
    "    print(f\"  [!] Failed to load {url} after {retries} attempts.\")\n",
    "    return None\n",
    "\n",
    "def extract_links_generic(soup, country_name):\n",
    "    \"\"\"\n",
    "    Scans the page for links that look like stadium profiles.\n",
    "    \"\"\"\n",
    "    stadiums = []\n",
    "    # Find all 'a' tags with an href\n",
    "    links = soup.find_all('a', href=True)\n",
    "    \n",
    "    for link in links:\n",
    "        href = link['href']\n",
    "        text = link.get_text(strip=True)\n",
    "        \n",
    "        # FILTERS:\n",
    "        # 1. Must be on stadiumguide.com\n",
    "        # 2. Must NOT be a known non-stadium page\n",
    "        # 3. Link text must be substantial (> 3 chars)\n",
    "        if \"stadiumguide.com\" in href and len(text) > 3:\n",
    "            \n",
    "            # Bad keywords that indicate a navigation link, not a stadium\n",
    "            bad_keywords = [\n",
    "                \"category\", \"tournaments\", \"tickets\", \"about\", \"contact\", \n",
    "                \"privacy\", \"city-guides\", \"stadium-database\", \"future-stadiums\",\n",
    "                \"past-stadiums\", \"tournament-stadiums\"\n",
    "            ]\n",
    "            \n",
    "            if not any(x in href for x in bad_keywords):\n",
    "                # Ensure we aren't linking back to a country/league list page\n",
    "                if \"stadiums\" not in href and \"/present/\" not in href:\n",
    "                    # Specific check to avoid linking to the country page itself (e.g. /italy/)\n",
    "                    if href.strip('/').split('/')[-1] != country_name.lower():\n",
    "                        stadiums.append({\n",
    "                            \"Country\": country_name,\n",
    "                            \"Stadium_Name_Overview\": text,\n",
    "                            \"Stadium_URL\": href\n",
    "                        })\n",
    "    return stadiums\n",
    "\n",
    "def scrape_country_overview(country_name, url):\n",
    "    print(f\"Scraping Country: {country_name}...\")\n",
    "    \n",
    "    soup = get_soup_with_retry(url)\n",
    "    if not soup: return []\n",
    "    \n",
    "    # STRATEGY 1: \"Nuclear Option\" - Scan the main content area\n",
    "    # Country pages often use a 'main' tag or 'div.entry-content'\n",
    "    main_area = soup.find('main') or soup.find('div', class_='entry-content') or soup.body\n",
    "    \n",
    "    links = extract_links_generic(main_area, country_name)\n",
    "    \n",
    "    # Deduplicate URLs found on the page\n",
    "    unique_links = []\n",
    "    seen = set()\n",
    "    for l in links:\n",
    "        if l['Stadium_URL'] not in seen:\n",
    "            unique_links.append(l)\n",
    "            seen.add(l['Stadium_URL'])\n",
    "            \n",
    "    print(f\"  -> Found {len(unique_links)} stadiums in {country_name}.\")\n",
    "    return unique_links\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "all_country_data = []\n",
    "\n",
    "for country, url in COUNTRY_MAP:\n",
    "    data = scrape_country_overview(country, url)\n",
    "    all_country_data.extend(data)\n",
    "    time.sleep(random.uniform(1.0, 2.0)) # Be polite\n",
    "\n",
    "# Create Master DataFrame\n",
    "df_country_pages = pd.DataFrame(all_country_data)\n",
    "\n",
    "# Remove duplicates (sometimes stadiums appear in multiple lists)\n",
    "if not df_country_pages.empty:\n",
    "    df_country_pages = df_country_pages.drop_duplicates(subset=['Stadium_URL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9095fcb9-26d8-4a4d-b578-00b02812fe9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting deep scrape for 409 stadiums...\n[1/409] Scraping: Oakwell Stadium...\r[2/409] Scraping: Villa Park...\r[3/409] Scraping: St Andrew's Stadium...\r[4/409] Scraping: Ewood Park...\r[5/409] Scraping: Bloomfield Road...\r[6/409] Scraping: University of Bolton Stadium...\r[7/409] Scraping: Vitality Stadium...\r[8/409] Scraping: Coral Windows Stadium...\r[9/409] Scraping: The Amex...\r[10/409] Scraping: Ashton Gate Stadium...\r[11/409] Scraping: Memorial Stadium...\r[12/409] Scraping: Turf Moor...\r[13/409] Scraping: Gigg Lane...\r[14/409] Scraping: Coventry Building Society Arena...\r[15/409] Scraping: Victoria Road...\r[16/409] Scraping: The iPro Stadium...\r[17/409] Scraping: Keepmoat Stadium...\r[18/409] Scraping: Highbury Stadium...\r[19/409] Scraping: Priestfield Stadium...\r[20/409] Scraping: John Smith's Stadium...\r[21/409] Scraping: MKM Stadium...\r[22/409] Scraping: Portman Road...\r[23/409] Scraping: Elland Road...\r[24/409] Scraping: King Power Stadium...\r[25/409] Scraping: Goodison Park...\r[26/409] Scraping: Anfield...\r[27/409] Scraping: Emirates Stadium...\r[28/409] Scraping: Brentford Community Stadium...\r[29/409] Scraping: The Valley...\r[30/409] Scraping: Stamford Bridge...\r[31/409] Scraping: Selhurst Park...\r[32/409] Scraping: Craven Cottage...\r[33/409] Scraping: The Matchroom Stadium...\r[34/409] Scraping: The Den...\r[35/409] Scraping: Loftus Road...\r[36/409] Scraping: Tottenham Hotspur Stadium...\r[37/409] Scraping: London Stadium...\r[38/409] Scraping: Wembley Stadium...\r[39/409] Scraping: Kenilworth Road...\r[40/409] Scraping: Etihad Stadium...\r[41/409] Scraping: Old Trafford...\r[42/409] Scraping: Riverside Stadium...\r[43/409] Scraping: St James Park...\r[44/409] Scraping: Carrow Road...\r[45/409] Scraping: City Ground...\r[46/409] Scraping: Meadow Lane...\r[47/409] Scraping: The Kassam Stadium...\r[48/409] Scraping: ABAX Stadium...\r[49/409] Scraping: Fratton Park...\r[50/409] Scraping: Deepdale...\r[51/409] Scraping: Madejski Stadium...\r[52/409] Scraping: Crown Oil Arena...\r[53/409] Scraping: New York Stadium...\r[54/409] Scraping: Glanford Park...\r[55/409] Scraping: Bramall Lane...\r[56/409] Scraping: Hillsborough...\r[57/409] Scraping: Montgomery Waters Stadium...\r[58/409] Scraping: St Mary's Stadium...\r[59/409] Scraping: Roots Hall Stadium...\r[60/409] Scraping: The Lamex Stadium...\r[61/409] Scraping: bet365 Stadium...\r[62/409] Scraping: Stadium of Light...\r[63/409] Scraping: Vicarage Road...\r[64/409] Scraping: The Hawthorns...\r[65/409] Scraping: DW Stadium...\r[66/409] Scraping: Molineux Stadium...\r[67/409] Scraping: Camp Nou...\r[68/409] Scraping: Bernabeu...\r[69/409] Scraping: Estadio ABANCA-Riazor...\r[70/409] Scraping: Estadio Municipal de Santo Domingo...\r[71/409] Scraping: Estadio Jose Rico Perez...\r[72/409] Scraping: Estadio de los Juegos Mediterraneos...\r[73/409] Scraping: Campo de Lasesarre...\r[74/409] Scraping: RCDE Stadium...\r[75/409] Scraping: Estadio San Mames...\r[76/409] Scraping: Nuevo Estadio Ramon de Carranza...\r[77/409] Scraping: Estadio Cartagonova...\r[78/409] Scraping: Estadio El Arcangel...\r[79/409] Scraping: Estadio de Ipurua...\r[80/409] Scraping: Estadio Martinez Valero...\r[81/409] Scraping: Coliseum Alfonso Perez...\r[82/409] Scraping: Estadio El Molinon...\r[83/409] Scraping: Estadi Municipal de Montilivi...\r[84/409] Scraping: Estadio de Los Carmenes...\r[85/409] Scraping: Estadio El Alcoraz...\r[86/409] Scraping: Stadium Gal...\r[87/409] Scraping: Estadio de Gran Canaria...\r[88/409] Scraping: Estadio Municipal de Butarque...\r[89/409] Scraping: Estadio Las Gaunas...\r[90/409] Scraping: Wanda Metropolitano...\r[91/409] Scraping: Campo de Futbol de Vallecas...\r[92/409] Scraping: Estadio Alfredo di Stefano...\r[93/409] Scraping: Estadio La Rosaleda...\r[94/409] Scraping: Estadio Enrique Roca de Murcia...\r[95/409] Scraping: Estadio Carlos Tartiere...\r[96/409] Scraping: Iberostar Estadio...\r[97/409] Scraping: Estadio El Sadar...\r[98/409] Scraping: Estadio Municipal El Toralin...\r[99/409] Scraping: Estadi Municipal de la Nova Creu Alta...\r[100/409] Scraping: Reale Arena...\r[101/409] Scraping: Estadio Heliodoro Rodriguez Lopez...\r[102/409] Scraping: Campos de Sport de El Sardinero...\r[103/409] Scraping: Estadio La Cartuja de Sevilla...\r[104/409] Scraping: Estadio Benito Villamarin...\r[105/409] Scraping: Estadio Ramon Sanchez Pizjuan...\r[106/409] Scraping: Nuevo Estadio Los Pajaritos...\r[107/409] Scraping: Nou Estadi...\r[108/409] Scraping: Estadi Ciutat de Valencia...\r[109/409] Scraping: Estadio de Mestalla...\r[110/409] Scraping: Estadio Jose Zorrilla...\r[111/409] Scraping: Estadio El Madrigal...\r[112/409] Scraping: Estadio Municipal de Balaidos...\r[113/409] Scraping: Estadio de Mendizorroza...\r[114/409] Scraping: Estadio La Romareda...\r[115/409] Scraping: Tivoli...\r[116/409] Scraping: Erzgebirgsstadion...\r[117/409] Scraping: WWK Arena...\r[118/409] Scraping: Stadion An der Alten Försterei...\r[119/409] Scraping: Olympiastadion...\r[120/409] Scraping: SchucoArena...\r[121/409] Scraping: Vonovia Ruhrstadion...\r[122/409] Scraping: Weserstadion...\r[123/409] Scraping: Eintracht-Stadion...\r[124/409] Scraping: RheinEnergieStadion...\r[125/409] Scraping: Stadion der Freundschaft...\r[126/409] Scraping: Stadion am Bollenfalltor...\r[127/409] Scraping: Signal Iduna Park...\r[128/409] Scraping: Rudolf-Harbig-Stadion...\r[129/409] Scraping: Schauinsland-Reisen-Stadion...\r[130/409] Scraping: Merkur Spiel Arena...\r[131/409] Scraping: Stadion Essen...\r[132/409] Scraping: Deutsche Bank Park...\r[133/409] Scraping: Schwarzwald-Stadion...\r[134/409] Scraping: Sportpark Ronhof...\r[135/409] Scraping: VELTINS-Arena...\r[136/409] Scraping: Volksparkstadion...\r[137/409] Scraping: Millerntor-Stadion...\r[138/409] Scraping: HDI Arena...\r[139/409] Scraping: Audi Sportpark...\r[140/409] Scraping: Fritz-Walter-Stadion...\r[141/409] Scraping: Holstein-Stadion...\r[142/409] Scraping: Red Bull Arena...\r[143/409] Scraping: BayArena...\r[144/409] Scraping: MDCC-Arena...\r[145/409] Scraping: MEWA Arena...\r[146/409] Scraping: Bruchwegstadion...\r[147/409] Scraping: Borussia-Park...\r[148/409] Scraping: Allianz Arena...\r[149/409] Scraping: Grunwalder Stadion...\r[150/409] Scraping: Olympiastadion Munich...\r[151/409] Scraping: Max-Morlock-Stadion...\r[152/409] Scraping: Benteler-Arena...\r[153/409] Scraping: Jahnstadion Regensburg...\r[154/409] Scraping: PreZero Arena...\r[155/409] Scraping: Mercedes-Benz Arena...\r[156/409] Scraping: BRITA-Arena...\r[157/409] Scraping: Volkswagen Arena...\r[158/409] Scraping: Juventus Stadium...\r[159/409] Scraping: Stadio San Nicola...\r[160/409] Scraping: Stadio Ciro Vigorito...\r[161/409] Scraping: Stadio Atleti Azzurri d'Italia...\r[162/409] Scraping: Stadio Renato Dall'Ara...\r[163/409] Scraping: Stadio Mario Rigamonti...\r[164/409] Scraping: Stadio Sant'Elia...\r[165/409] Scraping: Stadio Angelo Massimio...\r[166/409] Scraping: Stadio G. Sinigaglia...\r[167/409] Scraping: Stadio Giovanni Zini...\r[168/409] Scraping: Stadio Ezio Scida...\r[169/409] Scraping: Stadio Carlo Castellani...\r[170/409] Scraping: Stadio Paolo Mazza...\r[171/409] Scraping: Stadio Artemio Franchi...\r[172/409] Scraping: Stadio Benito Stirpe...\r[173/409] Scraping: Stadio Luigi Ferraris...\r[174/409] Scraping: Stadio Alberto Picco...\r[175/409] Scraping: Stadio Via Del Mare...\r[176/409] Scraping: Stadio Armando Picchi...\r[177/409] Scraping: San Siro...\r[178/409] Scraping: Stadio Alberto Braglia...\r[179/409] Scraping: Stadio Brianteo...\r[180/409] Scraping: Stadio San Paolo...\r[181/409] Scraping: Stadio Silvio Piola...\r[182/409] Scraping: Stadio Euganeo...\r[183/409] Scraping: Stadio Renzo Barbera...\r[184/409] Scraping: Stadio Ennio Tardini...\r[185/409] Scraping: Stadio Adriatico...\r[186/409] Scraping: Stadio Leonardo Garilli...\r[187/409] Scraping: MAPEI Stadium - Citta del Tricolore...\r[188/409] Scraping: Stadio Olimpico...\r[189/409] Scraping: Stadio Artemio Franchi...\r[190/409] Scraping: Stadio Olimpico di Torino...\r[191/409] Scraping: Stadio Friuli...\r[192/409] Scraping: Stadio Franco Ossola...\r[193/409] Scraping: Stadio Pierluigi Penzo...\r[194/409] Scraping: Stadio Marcantonio Bentegodi...\r[195/409] Scraping: Stade Francois Coty...\r[196/409] Scraping: Stade de la Licorne...\r[197/409] Scraping: Stade Raymond Kopa...\r[198/409] Scraping: Parc des Sports...\r[199/409] Scraping: Stade Abbe Deschamps...\r[200/409] Scraping: Stade Armand Cesari...\r[201/409] Scraping: Matmut Atlantique...\r[202/409] Scraping: Stade Chaban-Delmas...\r[203/409] Scraping: Stade Marcel Verchere...\r[204/409] Scraping: Stade Francis-Le Ble...\r[205/409] Scraping: Stade Michel d'Ornano...\r[206/409] Scraping: Stade Gaston Petit...\r[207/409] Scraping: Stade Gaston-Gerard...\r[208/409] Scraping: Stade des Alpes...\r[209/409] Scraping: Stade du Roudourou...\r[210/409] Scraping: Stade Oceane...\r[211/409] Scraping: MMArena...\r[212/409] Scraping: Stade Bollaert-Delelis...\r[213/409] Scraping: Stade Pierre Mauroy...\r[214/409] Scraping: Stade du Moustoir...\r[215/409] Scraping: Groupama Stadium...\r[216/409] Scraping: Stade Gerland...\r[217/409] Scraping: Orange Velodrome...\r[218/409] Scraping: Stade Saint-Symphorien...\r[219/409] Scraping: Stade Louis II...\r[220/409] Scraping: Stade Auguste Bonal...\r[221/409] Scraping: Stade de la Mosson...\r[222/409] Scraping: Stade Marcel-Picot...\r[223/409] Scraping: Stade de La Beaujoire...\r[224/409] Scraping: Allianz Riviera...\r[225/409] Scraping: Stade des Costieres...\r[226/409] Scraping: Stade Rene Gaillard...\r[227/409] Scraping: Stade Charlety...\r[228/409] Scraping: Parc des Princes...\r[229/409] Scraping: Stade Auguste Delaune...\r[230/409] Scraping: Roazhon Park...\r[231/409] Scraping: Stade de France...\r[232/409] Scraping: Stade Geoffroy Guichard...\r[233/409] Scraping: Stade de la Meinau...\r[234/409] Scraping: Stadium de Toulouse...\r[235/409] Scraping: Stade de l'Aube...\r[236/409] Scraping: Stade du Hainaut...\r[237/409] Scraping: Estadio Municipal de Aveiro...\r[238/409] Scraping: Estadio Municipal de Braga...\r[239/409] Scraping: Estadio EFAPEL Cidade de Coimbra...\r[240/409] Scraping: Estadio Nacional...\r[241/409] Scraping: Estadio Algarve...\r[242/409] Scraping: Estadio do Maritimo...\r[243/409] Scraping: Estadio D. Afonso Henriques...\r[244/409] Scraping: Estadio Municipal de Leiria...\r[245/409] Scraping: Estadio do Restelo...\r[246/409] Scraping: Estadio da Luz...\r[247/409] Scraping: Estadio Jose Alvalade...\r[248/409] Scraping: Estádio Com. Joaq. de Almeida Freitas...\r[249/409] Scraping: Estadio do Bessa XXI...\r[250/409] Scraping: Estadio do Dragao...\r[251/409] Scraping: Estadio do CD Aves...\r[252/409] Scraping: De Kuip...\r[253/409] Scraping: AFAS stadion...\r[254/409] Scraping: Erve Asito...\r[255/409] Scraping: Amsterdam ArenA...\r[256/409] Scraping: GelreDome...\r[257/409] Scraping: Rat Verlegh Stadion...\r[258/409] Scraping: Stadion De Vliert...\r[259/409] Scraping: Stadion De Vijverberg...\r[260/409] Scraping: Philips Stadion...\r[261/409] Scraping: Grolsch Veste...\r[262/409] Scraping: Stadion Euroborg...\r[263/409] Scraping: Abe Lenstra Stadion...\r[264/409] Scraping: SolarUnie Stadion...\r[265/409] Scraping: Parkstad Limburg Stadion...\r[266/409] Scraping: Goffertstadion...\r[267/409] Scraping: Het Kasteel...\r[268/409] Scraping: Stadion Woudestein...\r[269/409] Scraping: Fortuna Sittard Stadion...\r[270/409] Scraping: Stadion Galgenwaard...\r[271/409] Scraping: Cars Jeans Stadion...\r[272/409] Scraping: Willem II Stadion...\r[273/409] Scraping: Covebo Stadion De Koel -...\r[274/409] Scraping: Kras Stadion...\r[275/409] Scraping: Mandemakers Stadion...\r[276/409] Scraping: MAC3PARK Stadion...\r[277/409] Scraping: Olympisch Stadion...\r[278/409] Scraping: Bosuilstadion...\r[279/409] Scraping: Jan Breydel Stadion...\r[280/409] Scraping: Constant Vanden Stock Stadion...\r[281/409] Scraping: Stade Roi Baudouin...\r[282/409] Scraping: Stade du Pays Charleroi...\r[283/409] Scraping: Kehrweg-Stadion...\r[284/409] Scraping: Cristal Arena...\r[285/409] Scraping: Ghelamco Arena...\r[286/409] Scraping: Guldensporenstadion...\r[287/409] Scraping: Stadion den Dreef...\r[288/409] Scraping: Stade de Sclessin...\r[289/409] Scraping: Daknamstadion...\r[290/409] Scraping: Stade du Cannonier...\r[291/409] Scraping: Stayen...\r[292/409] Scraping: Regenboogstadion...\r[293/409] Scraping: Akhisar Arena...\r[294/409] Scraping: Akdeniz Universitesi-Stadion...\r[295/409] Scraping: Timsah Arena...\r[296/409] Scraping: Kamil Ocak Stadyumu...\r[297/409] Scraping: Kadir Has Stadyumu...\r[298/409] Scraping: Vodafone Arena...\r[299/409] Scraping: Sukru Saracoglu Stadyumu...\r[300/409] Scraping: Turk Telekom Arena...\r[301/409] Scraping: Fatih Terim Stadium...\r[302/409] Scraping: Recep Tayyip Erdogan Stadium...\r[303/409] Scraping: Ataturk Olimpiyat Stadi...\r[304/409] Scraping: Konya Buyuksehir Torku Arena...\r[305/409] Scraping: Sivas 4 Eylul Stadyumu...\r[306/409] Scraping: Medical Park Arena...\r[307/409] Scraping: OAKA Stadium...\r[308/409] Scraping: Peristeri Stadium...\r[309/409] Scraping: Nea Smyrni Stadium...\r[310/409] Scraping: Apostolos Nikolaidis Stadium...\r[311/409] Scraping: Karaiskakis Stadium...\r[312/409] Scraping: Kleanthis Vikelidis Stadium...\r[313/409] Scraping: Toumba Stadium...\r[314/409] Scraping: Xanthi FC Arena...\r[315/409] Scraping: Aalborg Portland Park...\r[316/409] Scraping: Ceres Park...\r[317/409] Scraping: Brondby Stadion...\r[318/409] Scraping: Telia Parken...\r[319/409] Scraping: Right to Dream Park...\r[320/409] Scraping: Sydbank Park...\r[321/409] Scraping: MCH Arena...\r[322/409] Scraping: Nature Energy Park...\r[323/409] Scraping: JYSK Park...\r[324/409] Scraping: CASHPOINT Arena Altach...\r[325/409] Scraping: Merkur-Arena...\r[326/409] Scraping: Tivoli Stadion Tirol...\r[327/409] Scraping: Worthersee Stadion...\r[328/409] Scraping: BSFZ-Arena...\r[329/409] Scraping: Josko Arena...\r[330/409] Scraping: Red Bull Arena...\r[331/409] Scraping: NV Arena...\r[332/409] Scraping: Generali Arena...\r[333/409] Scraping: Allianz Stadion...\r[334/409] Scraping: Ernst Happel Stadion...\r[335/409] Scraping: Lavanttal-Arena...\r[336/409] Scraping: Stadion Miejski w Bialymstoku...\r[337/409] Scraping: Stadion Miejski w Bielsku-Bialej...\r[338/409] Scraping: Stadion Slaski...\r[339/409] Scraping: Stadion Ruchu Chorzow...\r[340/409] Scraping: Stadion Energa Gdansk...\r[341/409] Scraping: Stadion Miejski w Gdyni...\r[342/409] Scraping: Stadion Miejski w Gliwicach...\r[343/409] Scraping: Stadion Miejski Katowice...\r[344/409] Scraping: Stadion Miejski w Kielcach...\r[345/409] Scraping: Stadion Cracovii...\r[346/409] Scraping: Stadion Miejski im. Henryka Reymana...\r[347/409] Scraping: Stadion Zaglebia Lubin...\r[348/409] Scraping: Arena Lublin...\r[349/409] Scraping: INEA Stadion...\r[350/409] Scraping: Stadion Miejski im. Floriana Krygiera...\r[351/409] Scraping: Stadion Miejski Tychy...\r[352/409] Scraping: Stadion Miejski Legii Warszawa...\r[353/409] Scraping: Stadion Narodowy w Warszawie...\r[354/409] Scraping: Stadion Miejski w Wroclawiu...\r[355/409] Scraping: Arena Zabrze...\r[356/409] Scraping: Dnipro Arena...\r[357/409] Scraping: Donbass Arena...\r[358/409] Scraping: Metalist Stadium...\r[359/409] Scraping: NSC Olimpiyskiy...\r[360/409] Scraping: Stadion Metalurh...\r[361/409] Scraping: Stadion Avanhard...\r[362/409] Scraping: Arena Lviv...\r[363/409] Scraping: Stadion Chornomorets...\r[364/409] Scraping: Stadion CSC Nika...\r[365/409] Scraping: Stadion Vorskla...\r[366/409] Scraping: Stadion Gradski vrt...\r[367/409] Scraping: Stadion Aldo Drosina...\r[368/409] Scraping: Stadion Kantrida...\r[369/409] Scraping: Stadion Poljud...\r[370/409] Scraping: Stadion Maksimir...\r[371/409] Scraping: Stadion SRC Zapresic...\r[372/409] Scraping: Fisht Olympic Stadium...\r[373/409] Scraping: Kaliningrad Stadium...\r[374/409] Scraping: Kazan Arena...\r[375/409] Scraping: Arena Khimki...\r[376/409] Scraping: FC Krasnodar Stadium...\r[377/409] Scraping: Stadion Kuban...\r[378/409] Scraping: Dinamo Stadium Makhachkala...\r[379/409] Scraping: VTB Arena...\r[380/409] Scraping: RZD Arena...\r[381/409] Scraping: Otkritie Arena...\r[382/409] Scraping: Arena CSKA...\r[383/409] Scraping: Sports Complex E.A. Streltsov...\r[384/409] Scraping: Luzhniki Stadium...\r[385/409] Scraping: Nizhny Novgorod Stadium...\r[386/409] Scraping: Spartak Stadium...\r[387/409] Scraping: Petrovsky Stadium...\r[388/409] Scraping: Gazprom Arena...\r[389/409] Scraping: Cosmos Arena...\r[390/409] Scraping: Mordovia Arena...\r[391/409] Scraping: Ekaterinburg Arena...\r[392/409] Scraping: Stadion Spartak...\r[393/409] Scraping: Volgograd Arena...\r[394/409] Scraping: Celtic Park...\r[395/409] Scraping: Hampden Park...\r[396/409] Scraping: Ibrox...\r[397/409] Scraping: Pittodrie Stadium...\r[398/409] Scraping: Global Energy Stadium...\r[399/409] Scraping: Bet Butler Stadium...\r[400/409] Scraping: Dens Park...\r[401/409] Scraping: Tynecastle Stadium...\r[402/409] Scraping: Easter Road Stadium...\r[403/409] Scraping: Firhill Stadium...\r[404/409] Scraping: SuperSeal Stadium...\r[405/409] Scraping: Rugby Park...\r[406/409] Scraping: Tulloch Caledonian Stadium...\r[407/409] Scraping: Fir Park...\r[408/409] Scraping: St Mirren Park...\r[409/409] Scraping: McDiarmid Park...\r\n\n========================================\nScraping Complete! Collected data for 409 stadiums.\n========================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. SETUP & PROXIES\n",
    "# ==========================================\n",
    "# (Same configuration as before)\n",
    "PASSWORD = os.getenv('BRIGHTDATA_PASSWORD', 'YOUR_PASSWORD_HERE')\n",
    "BASE_USERNAME = os.getenv('BRIGHTDATA_USER', 'YOUR_ZONE_USERNAME_HERE') \n",
    "HOST = 'brd.superproxy.io'\n",
    "PORT = '33335'\n",
    "country_code = \"hu\" \n",
    "session_id = random.randint(1, 1000000)\n",
    "FINAL_USERNAME = f\"{BASE_USERNAME}-country-{country_code}-session-{session_id}\"\n",
    "\n",
    "PROXIES = {\n",
    "    'http': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}', \n",
    "    'https': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}'\n",
    "}\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. HELPER FUNCTIONS (TEXT EXTRACTION)\n",
    "# ==========================================\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Removes extra whitespace and newlines.\"\"\"\n",
    "    if not text: return \"Info not available\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def get_section_text(soup, patterns):\n",
    "    \"\"\"\n",
    "    Scans for headers matching specific keywords (Directions, Tickets, etc.)\n",
    "    and extracts the paragraphs following them.\n",
    "    \"\"\"\n",
    "    header = None\n",
    "    # Search for header tags (h2-h5, strong) matching patterns\n",
    "    for tag in ['h2', 'h3', 'h4', 'h5', 'strong']: \n",
    "        for pattern in patterns:\n",
    "            header = soup.find(tag, string=re.compile(pattern, re.IGNORECASE))\n",
    "            if header: break\n",
    "        if header: break\n",
    "    \n",
    "    if not header: return \"Info not available\"\n",
    "\n",
    "    content = []\n",
    "    curr = header.find_next_sibling()\n",
    "    while curr:\n",
    "        # Stop reading if we hit the next major header or footer\n",
    "        if curr.name in ['h2', 'h3', 'div', 'footer']:\n",
    "             # Only stop if the header actually has text (avoids empty tags stopping the scraper)\n",
    "            if curr.get_text(strip=True): break\n",
    "        \n",
    "        # Collect text from paragraphs and lists\n",
    "        if curr.name in ['p', 'ul', 'ol']:\n",
    "            text = curr.get_text(strip=True)\n",
    "            if len(text) > 5: content.append(text)\n",
    "        \n",
    "        curr = curr.find_next_sibling()\n",
    "        \n",
    "    return clean_text(\" \".join(content)) if content else \"Info not available\"\n",
    "\n",
    "def parse_stadium_page(url, country):\n",
    "    \"\"\"\n",
    "    Visits a single stadium URL and extracts ALL data fields.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"Country\": country,\n",
    "        \"Stadium\": None,\n",
    "        \"City\": \"Info not available\",\n",
    "        \"Home Team\": \"Info not available\",\n",
    "        \"Capacity\": None,\n",
    "        \"Directions\": \"Info not available\",\n",
    "        \"Food_and_Stay\": \"Info not available\",\n",
    "        \"Ticket_Info\": \"Info not available\",\n",
    "        \"URL\": url\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, proxies=PROXIES, headers=HEADERS, verify=False, timeout=15)\n",
    "        if r.status_code != 200: return data \n",
    "        \n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        # --- 1. BASIC INFO ---\n",
    "        # Stadium Name\n",
    "        title = soup.find('h1')\n",
    "        data['Stadium'] = title.get_text(strip=True) if title else \"Unknown\"\n",
    "\n",
    "        # Parsing the 'Stadfacts' table (common on StadiumGuide)\n",
    "        facts_table = soup.find('table', class_='stadfacts')\n",
    "        if facts_table:\n",
    "            for row in facts_table.find_all('tr'):\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) >= 2:\n",
    "                    key = cells[0].get_text(strip=True).lower()\n",
    "                    val = cells[1].get_text(strip=True)\n",
    "                    \n",
    "                    if \"club\" in key or \"team\" in key:\n",
    "                        data[\"Home Team\"] = val\n",
    "                    elif \"location\" in key or \"city\" in key:\n",
    "                        data[\"City\"] = val\n",
    "                    elif \"capacity\" in key:\n",
    "                        # Clean \"75,000\" -> 75000\n",
    "                        clean_cap = re.sub(r'[^\\d]', '', val)\n",
    "                        if clean_cap: data[\"Capacity\"] = int(clean_cap)\n",
    "        \n",
    "        # Fallback: If table is missing, use Regex on the body text\n",
    "        content_div = soup.find('div', class_='entry-content')\n",
    "        content_text = content_div.get_text(\" \", strip=True) if content_div else \"\"\n",
    "\n",
    "        if data[\"Home Team\"] == \"Info not available\":\n",
    "            match = re.search(r'(?:Team|Club):\\s*([A-Za-z0-9\\s]+)', content_text)\n",
    "            if match: data[\"Home Team\"] = match.group(1).strip()\n",
    "            \n",
    "        if not data[\"Capacity\"]:\n",
    "            match = re.search(r'Capacity:\\s*([0-9,]+)', content_text)\n",
    "            if match:\n",
    "                clean_cap = re.sub(r'[^\\d]', '', match.group(1))\n",
    "                if clean_cap: data[\"Capacity\"] = int(clean_cap)\n",
    "\n",
    "        # --- 2. RICH TEXT SECTIONS ---\n",
    "        # Regex patterns to capture variations in headings\n",
    "        d_pats = [r\"How to get to\", r\"Getting to\", r\"Transport\", r\"Location\", r\"Directions\", r\"Arriving\"]\n",
    "        f_pats = [r\"Eat, drink\", r\"Food\", r\"Restaurants\", r\"Hotels\", r\"Sleep\", r\"Where to stay\"]\n",
    "        t_pats = [r\"Tickets\", r\"Admissions\", r\"Buying tickets\", r\"Entry\"]\n",
    "\n",
    "        data['Directions'] = get_section_text(soup, d_pats)\n",
    "        data['Food_and_Stay'] = get_section_text(soup, f_pats)\n",
    "        data['Ticket_Info'] = get_section_text(soup, t_pats)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {url}: {e}\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "# ==========================================\n",
    "# 3. MAIN EXECUTION LOOP\n",
    "# ==========================================\n",
    "\n",
    "print(f\"Starting deep scrape for {len(df_country_pages)} stadiums...\")\n",
    "full_stadium_data = []\n",
    "\n",
    "# Convert DataFrame to list of dicts for faster iteration\n",
    "stadium_list = df_country_pages.to_dict('records')\n",
    "\n",
    "for i, row in enumerate(stadium_list):\n",
    "    url = row['Stadium_URL']\n",
    "    cntry = row['Country']\n",
    "    \n",
    "    # Progress Bar\n",
    "    print(f\"[{i+1}/{len(stadium_list)}] Scraping: {row['Stadium_Name_Overview']}...\", end=\"\\r\")\n",
    "    \n",
    "    # Scrape\n",
    "    details = parse_stadium_page(url, cntry)\n",
    "    full_stadium_data.append(details)\n",
    "    \n",
    "    # Polite sleep\n",
    "    time.sleep(random.uniform(0.5, 1.2))\n",
    "\n",
    "# ==========================================\n",
    "# 4. FINAL OUTPUT\n",
    "# ==========================================\n",
    "\n",
    "df_stadiums_enriched = pd.DataFrame(full_stadium_data)\n",
    "\n",
    "# Reorder columns nicely\n",
    "cols = ['Country', 'Stadium', 'Directions', 'Food_and_Stay', 'Ticket_Info']\n",
    "        \n",
    "# Select only columns that exist\n",
    "final_cols = [c for c in cols if c in df_stadiums_enriched.columns]\n",
    "df_stadiums_enriched = df_stadiums_enriched[final_cols]\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*40)\n",
    "print(f\"Scraping Complete! Collected data for {len(df_stadiums_enriched)} stadiums.\")\n",
    "print(\"=\"*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34e4a3a5-ba5f-478b-9d64-3fdfb7a72e98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Country</th><th>Stadium</th><th>Directions</th><th>Food_and_Stay</th><th>Ticket_Info</th></tr></thead><tbody><tr><td>England</td><td>Oakwell Stadium</td><td>Oakwell Stadium is located just east of Barnsley’s town centre and rail station. The walk will only take 5 to 10 minutes. Barnsley is serviced with directtrainsfrom, among others, Sheffield, Leeds, and Huddersfield. Address: Grove Street, Barnsley, S71 1ET</td><td>Info not available</td><td>Tickets for Barnsley matches can be boughtonline, or at the ticket office at the stadium. Tickets can also be bought at the turnstiles on the day of the match. Ticket prices are the same for all stands, but depend on the opponent. The cheapest go for £23.00, while tickets for the most expensive opponents cost £36.00. Tickets are £2.00 more expensive if bought on the day. For more information emailboxoffice@barnsleyfc.co.ukor call +44 (0)871 2266777.</td></tr><tr><td>England</td><td>Villa Park</td><td>Info not available</td><td>Villa Park is located in a typical English urban area. This means that there are a few pubs around as well as some easy eating options, though if you have more time on your hands, Birmingham’s city centre might be a better option. If you arrive by car, you could stop at theStar Cityshopping centre just off exit 6 of the M6. It has the typical food outlets you tend to find at a shopping centre as well as various entertainment options. The nightlife in Birmingham’s city centre is mostly located west and south of Birmingham New Street Station. There are few hotels in the immediate vicinity of the stadium. TheHoliday Inn Expresslocated across Star City shopping centre is probably closest, but is mostly convenient if you get in by car. You can about just walk to the stadium from there. Further toward the centre, there are aCampanile HotelandPremier Inn. They are affordable and get good reviews, but are again most of all convenient for those arriving by car. If travelling by public transport, it is likely best to find a hotel in Birmingham’s centre, and take a bus or train to the match. For all hotels near Villa Park clickhere. For all options in the city centre gohere.</td><td>Tickets for Aston Villa matches can be boughtonline, by phone +44 (0) 800 6120 970, or at the Villa Village store at Villa Park. Tickets can also be bought at the same store before the start of the match. Aston Villa only very occasionally sell out. Aston Villa have divided their home games in three pricing categories. Tickets for category A matches, the most expensive, range in price from £25.00 for a lower-tier seat at the North Stand to £45.00 for a central seat at one of the long sides. Tickets for category VV matches, the cheapest, range in price from £20.00 to £37.00.</td></tr><tr><td>England</td><td>St. Andrew’s Stadium</td><td>Info not available</td><td>St. Andrew’s Stadium is located in a rather quiet residential area with little around. As usual in England, there is always the odd pub, though you find many more options in Birmingham’s city centre, which is not far away. There are, for example, various eating and drinking options south of Birmingham New Street Station, from where one can walk or catch a bus to the ground. There is anIbis Hotela few minutes walking from St. Andrew’s, whileRoyal George Hotellies right at the back of the stadium. Both are reasonably priced and get acceptable reviews.The Moseley Armsis a similar alternative located slightly more toward the city centre. Clickherefor all hotels near St. Andrew’s Stadium. If you have a little more time on your hands, staying in Birmingham’s city centre may be a better alternative though. In particular from one of the hotels just south of BirminghamNew Street Stationit won’t be too hard to get to the stadium.</td><td>Tickets for Birmingham City games can be purchasedonline, by phone +44 (0) 844 557 1875, or in person at the Ticket Office at St. Andrew’s Stadium. If tickets remain, these can also be bought on the day of the match at the stadium. Birmingham City rarely sells out in the Championship. Ticket prices typically range from £25.00 for an upper-tier seat behind the goal to £30.00 for a seat at one of the long sides. Tickets are £5.00 cheaper if bought in pre-sale. For more information emailticket.office@bhfc.comor call+44 (0) 844 557 1875.</td></tr><tr><td>England</td><td>Ewood Park</td><td>Ewood Park is located in the south of Blackburn, about 1.5 miles from Blackburn’s town centre and main railway station. Mill Hill railway station lies somewhat closer to the ground though, less than one mile. Trains run about once an hour from Blackburn Rail and Manchester Victoria station. Another option is to catch a bus from Blackburn’s town centre or rail station. Bus 1 and 225 leave from the bus station opposite the rail station. Get off at stop Hollin Bank. Buses leave at least every 10 minutes for the 11-minute ride. Arriving by car from the M65 (which runs south of Blackburn), take junction 4. Follow signs for Blackburn. Ewood Park will show up on your right after about a mile on Bolton Road. Address: Ewood Park, Blackburn, Lancashire, BB2 4JF</td><td>Info not available</td><td>Tickets for Blackburn Rovers matches can be boughtonline, or in person at the Roverstore at the stadium. Blackburn almost never sell out, though they may restrict ticket sales to local fans only for certain high-profile marches. Ticket prices can depend on the opponent. Expect to pay from £15.00 for a seat at the single-tiered Riverside Stand to £25.00 for a central seat at the Jack Walker Stand for a typical match. Tickets for high-profile matches can be up to £5.00 more expensive.</td></tr><tr><td>England</td><td>Bloomfield Road</td><td>Bloomfield Road is located in central Blackpool, just south of Blackpool town centre and at only a few hundred metres from the Promenade (between the South and Central Pier). Blackpool Southrailstation lies at just a 5 to 10-minute walk away from the ground, though the station is only served by regional trains. From Blackpool’s main rail station (North) it is a 20 to 30-minute walk to the ground. Address: Seasiders Way, Blackpool, FY1 6JJ</td><td>Info not available</td><td>Tickets for Blackpool games can be boughtonline, by phone +44 (0) 844 847 1953, or at the ticket office at Bloomfield Road. Tickets cost either £22.00 for most seats or £27.00 for the most central places at the West Stand. For more information emailticketoffice@blackpoolfc.co.uk.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "England",
         "Oakwell Stadium",
         "Oakwell Stadium is located just east of Barnsley’s town centre and rail station. The walk will only take 5 to 10 minutes. Barnsley is serviced with directtrainsfrom, among others, Sheffield, Leeds, and Huddersfield. Address: Grove Street, Barnsley, S71 1ET",
         "Info not available",
         "Tickets for Barnsley matches can be boughtonline, or at the ticket office at the stadium. Tickets can also be bought at the turnstiles on the day of the match. Ticket prices are the same for all stands, but depend on the opponent. The cheapest go for £23.00, while tickets for the most expensive opponents cost £36.00. Tickets are £2.00 more expensive if bought on the day. For more information emailboxoffice@barnsleyfc.co.ukor call +44 (0)871 2266777."
        ],
        [
         "England",
         "Villa Park",
         "Info not available",
         "Villa Park is located in a typical English urban area. This means that there are a few pubs around as well as some easy eating options, though if you have more time on your hands, Birmingham’s city centre might be a better option. If you arrive by car, you could stop at theStar Cityshopping centre just off exit 6 of the M6. It has the typical food outlets you tend to find at a shopping centre as well as various entertainment options. The nightlife in Birmingham’s city centre is mostly located west and south of Birmingham New Street Station. There are few hotels in the immediate vicinity of the stadium. TheHoliday Inn Expresslocated across Star City shopping centre is probably closest, but is mostly convenient if you get in by car. You can about just walk to the stadium from there. Further toward the centre, there are aCampanile HotelandPremier Inn. They are affordable and get good reviews, but are again most of all convenient for those arriving by car. If travelling by public transport, it is likely best to find a hotel in Birmingham’s centre, and take a bus or train to the match. For all hotels near Villa Park clickhere. For all options in the city centre gohere.",
         "Tickets for Aston Villa matches can be boughtonline, by phone +44 (0) 800 6120 970, or at the Villa Village store at Villa Park. Tickets can also be bought at the same store before the start of the match. Aston Villa only very occasionally sell out. Aston Villa have divided their home games in three pricing categories. Tickets for category A matches, the most expensive, range in price from £25.00 for a lower-tier seat at the North Stand to £45.00 for a central seat at one of the long sides. Tickets for category VV matches, the cheapest, range in price from £20.00 to £37.00."
        ],
        [
         "England",
         "St. Andrew’s Stadium",
         "Info not available",
         "St. Andrew’s Stadium is located in a rather quiet residential area with little around. As usual in England, there is always the odd pub, though you find many more options in Birmingham’s city centre, which is not far away. There are, for example, various eating and drinking options south of Birmingham New Street Station, from where one can walk or catch a bus to the ground. There is anIbis Hotela few minutes walking from St. Andrew’s, whileRoyal George Hotellies right at the back of the stadium. Both are reasonably priced and get acceptable reviews.The Moseley Armsis a similar alternative located slightly more toward the city centre. Clickherefor all hotels near St. Andrew’s Stadium. If you have a little more time on your hands, staying in Birmingham’s city centre may be a better alternative though. In particular from one of the hotels just south of BirminghamNew Street Stationit won’t be too hard to get to the stadium.",
         "Tickets for Birmingham City games can be purchasedonline, by phone +44 (0) 844 557 1875, or in person at the Ticket Office at St. Andrew’s Stadium. If tickets remain, these can also be bought on the day of the match at the stadium. Birmingham City rarely sells out in the Championship. Ticket prices typically range from £25.00 for an upper-tier seat behind the goal to £30.00 for a seat at one of the long sides. Tickets are £5.00 cheaper if bought in pre-sale. For more information emailticket.office@bhfc.comor call+44 (0) 844 557 1875."
        ],
        [
         "England",
         "Ewood Park",
         "Ewood Park is located in the south of Blackburn, about 1.5 miles from Blackburn’s town centre and main railway station. Mill Hill railway station lies somewhat closer to the ground though, less than one mile. Trains run about once an hour from Blackburn Rail and Manchester Victoria station. Another option is to catch a bus from Blackburn’s town centre or rail station. Bus 1 and 225 leave from the bus station opposite the rail station. Get off at stop Hollin Bank. Buses leave at least every 10 minutes for the 11-minute ride. Arriving by car from the M65 (which runs south of Blackburn), take junction 4. Follow signs for Blackburn. Ewood Park will show up on your right after about a mile on Bolton Road. Address: Ewood Park, Blackburn, Lancashire, BB2 4JF",
         "Info not available",
         "Tickets for Blackburn Rovers matches can be boughtonline, or in person at the Roverstore at the stadium. Blackburn almost never sell out, though they may restrict ticket sales to local fans only for certain high-profile marches. Ticket prices can depend on the opponent. Expect to pay from £15.00 for a seat at the single-tiered Riverside Stand to £25.00 for a central seat at the Jack Walker Stand for a typical match. Tickets for high-profile matches can be up to £5.00 more expensive."
        ],
        [
         "England",
         "Bloomfield Road",
         "Bloomfield Road is located in central Blackpool, just south of Blackpool town centre and at only a few hundred metres from the Promenade (between the South and Central Pier). Blackpool Southrailstation lies at just a 5 to 10-minute walk away from the ground, though the station is only served by regional trains. From Blackpool’s main rail station (North) it is a 20 to 30-minute walk to the ground. Address: Seasiders Way, Blackpool, FY1 6JJ",
         "Info not available",
         "Tickets for Blackpool games can be boughtonline, by phone +44 (0) 844 847 1953, or at the ticket office at Bloomfield Road. Tickets cost either £22.00 for most seats or £27.00 for the most central places at the West Stand. For more information emailticketoffice@blackpoolfc.co.uk."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Stadium",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Directions",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Food_and_Stay",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Ticket_Info",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_stadiums_enriched.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcd48fa8-b483-4852-81b6-382dbc68a05d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\nCoords: 274 | Details: 409\nJoining...\nTotal: 274 | Matched: 243 | Missing: 31\nSaved successfully to: /dbfs/FileStore/Stadium_LLM_Enrichment.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import difflib\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. LOAD DATASETS\n",
    "# ==========================================\n",
    "print(\"Loading files...\")\n",
    "\n",
    "# Load from existing DataFrames\n",
    "df_coords = df_stadiums.toPandas() if hasattr(df_stadiums, 'toPandas') else df_stadiums.copy()\n",
    "df_details = df_stadiums_enriched.toPandas() if hasattr(df_stadiums_enriched, 'toPandas') else df_stadiums_enriched.copy()\n",
    "\n",
    "print(f\"Coords: {len(df_coords)} | Details: {len(df_details)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ADVANCED NORMALIZATION\n",
    "# ==========================================\n",
    "def normalize(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'\\[.*?\\]', '', s)\n",
    "    s = re.sub(r'\\(.*?\\)', '', s)\n",
    "    s = s.replace(\"'\", \"'\").replace(\"'\", \"'\").replace(\"-\", \" \")\n",
    "    s = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('utf-8')\n",
    "    return s.strip()\n",
    "\n",
    "df_coords['norm_stad'] = df_coords['Stadium'].apply(normalize)\n",
    "df_coords['norm_team'] = df_coords['Team'].apply(normalize)\n",
    "df_coords['norm_country'] = df_coords['Country'].apply(normalize)\n",
    "\n",
    "country_fix = {'the netherlands': 'netherlands', 'turkiye': 'turkey', 'czechia': 'czech republic'}\n",
    "\n",
    "stad_col = next((c for c in df_details.columns if 'stadium' in c.lower()), 'Stadium')\n",
    "cntry_col = next((c for c in df_details.columns if 'country' in c.lower()), 'Country')\n",
    "url_col = next((c for c in df_details.columns if 'url' in c.lower()), None)\n",
    "text_col = next((c for c in df_details.columns if 'directions' in c.lower()), 'Directions')\n",
    "\n",
    "df_details['norm_stad'] = df_details[stad_col].apply(normalize)\n",
    "df_details['norm_country'] = df_details[cntry_col].apply(lambda x: country_fix.get(normalize(x), normalize(x)))\n",
    "df_details['clean_url'] = df_details[url_col].astype(str).str.lower() if url_col else ''\n",
    "df_details['search_text'] = df_details[text_col].astype(str).str.lower() if text_col in df_details.columns else ''\n",
    "\n",
    "details_list = df_details.to_dict('records')\n",
    "\n",
    "# ==========================================\n",
    "# 3. MANUAL MAP\n",
    "# ==========================================\n",
    "manual_map = {\n",
    "    # --- SPAIN ---\n",
    "    \"anoeta\": \"reale arena\",\n",
    "    \"balaidos\": \"balaidos\",\n",
    "    \"mendizorrotza\": \"mendizorroza\",\n",
    "    \"san mames\": \"san mames\",\n",
    "    \"metropolitano\": \"wanda\",\n",
    "    \"olimpic lluis companys\": \"olimpic\",\n",
    "    \"ramon sanchez pizjuan\": \"sanchez pizjuan\",\n",
    "    \"benito villamarin\": \"benito villamarin\",\n",
    "    \"mestalla\": \"mestalla\",\n",
    "    \"coliseum\": \"alfonso perez\",\n",
    "    \"son moix\": \"iberostar\",\n",
    "    \"mallorca son moix\": \"iberostar\",\n",
    "    \n",
    "    # --- ITALY ---\n",
    "    \"unipol domus\": \"cagliari\",\n",
    "    \"gewiss stadium\": \"atleti azzurri\", \n",
    "    \"mapei stadium\": \"citta del tricolore\",\n",
    "    \"dacia arena\": \"friuli\",\n",
    "    \"bluenergy stadium\": \"friuli\",\n",
    "    \"stadio diego armando maradona\": \"san paolo\",\n",
    "    \n",
    "    # --- NETHERLANDS ---\n",
    "    \"de adelaarshorst\": \"go ahead\",\n",
    "    \"johan cruijff arena\": \"amsterdam arena\",\n",
    "    \"mac3park stadion\": \"ijsseldelta\",\n",
    "    \n",
    "    # --- BELGIUM ---\n",
    "    \"afas stadion achter de kazerne\": \"mechelen\",\n",
    "    \"het kuipje\": \"westerlo\",\n",
    "    \"lotto park\": \"vanden stock\",\n",
    "    \"cegeka arena\": \"luminus\",\n",
    "    \"planet group arena\": \"ghelamco\",\n",
    "    \"den dreef\": \"den dreef\",\n",
    "    \n",
    "    # --- TURKEY ---\n",
    "    \"corendon airlines park\": \"antalya\",\n",
    "    \"konya metropolitan municipality stadium\": \"torku\",\n",
    "    \"papara park\": \"senol gunes\",\n",
    "    \"rams park\": \"turk telekom\",\n",
    "    \"mersin stadium\": \"mersin\",\n",
    "    \"tupras stadyumu\": \"vodafone\",\n",
    "    \"ulker stadyumu\": \"sukru\",\n",
    "    \"medas konya\": \"torku\",\n",
    "    \"rize city stadium\": \"caykur didi\",\n",
    "    \"samsun 19 mayis stadium\": \"samsun 19 mayis\",\n",
    "    \"new adana stadium\": \"new adana\",\n",
    "    \"gursel aksel stadium\": \"gursel aksel\",\n",
    "    \"rhg enerturk enerji stadium\": \"kadir has\",\n",
    "\n",
    "    # --- AUSTRIA ---\n",
    "    \"profertil arena hartberg\": \"hartberg\",\n",
    "    \"stadion schnabelholz\": \"cashpoint\",\n",
    "    \"hofmann personal stadion\": \"donaupark\",\n",
    "    \"raiffeisen arena\": \"linzer\",\n",
    "\n",
    "    # --- CZECH REPUBLIC ---\n",
    "    \"dolicek\": \"dolicek\",\n",
    "    \"mestsky fotbalovy stadion miroslava valenty\": \"miroslava valenty\",\n",
    "    \"mestsky stadion karvina\": \"karvina\",\n",
    "    \"mestsky stadion ostrava\": \"mestsky stadion\",\n",
    "    \"na stinadlech\": \"na stinadlech\",\n",
    "\n",
    "    # --- DENMARK ---\n",
    "    \"ceres park\": \"atletion\",\n",
    "    \"energi viborg arena\": \"viborg\",\n",
    "    \"right to dream park\": \"farum\",\n",
    "\n",
    "    # --- POLAND ---\n",
    "    \"jozef pilsudski cracovia stadium\": \"cracovia\",\n",
    "    \"jozef pilsudski cracovia stadium3municipal stadium\": \"cracovia\",\n",
    "    \"gks katowice stadium1arena katowice\": \"gks katowice\",\n",
    "    \"ernest pohl stadium\": \"ernest pohl\",\n",
    "    \"exbud arena\": \"kielce city\",\n",
    "    \"polish army stadium\": \"polish army\",\n",
    "    \"motor lublin arena\": \"arena lublin\",\n",
    "    \"piotr wieczorek stadium\": \"piast\",\n",
    "    \"florian krygier stadium\": \"florian krygier\",\n",
    "    \"czachor brothers stadium\": \"radomiak\",\n",
    "    \"rakow municipal football stadium\": \"rakow\",\n",
    "    \"grzegorz lato stadium\": \"stal mielec\",\n",
    "    \"widzew lodz stadium\": \"widzew\",\n",
    "    \"kghm zaglebie arena\": \"zaglebie\",\n",
    "    \"polsat plus arena gdansk\": \"pge arena\",\n",
    "    \"tarczynski arena\": \"wroclaw\",\n",
    "    \"pge narodowy\": \"narodowy\",\n",
    "\n",
    "    # --- UKRAINE ---\n",
    "    \"lobanovskyi dynamo stadium\": \"dynamo stadium\",\n",
    "    \"berezkin zirka stadium\": \"zirka\",\n",
    "    \"butovsky vorskla stadium\": \"vorskla\",\n",
    "    \"avanhard stadium\": \"avanhard\",\n",
    "    \"nsc olimpiyskiy\": \"olimpiyskiy\",\n",
    "    \"csc nika stadium\": \"csc nika\",\n",
    "\n",
    "    # --- CROATIA ---\n",
    "    \"src velika gorica\": \"radnik\",\n",
    "    \"kranjceviceva1\": \"kranjceviceva\",\n",
    "    \"subicevac\": \"sibenik\",\n",
    "    \"opus arena\": \"gradski vrt\", \n",
    "    \n",
    "    # --- PREMIER LEAGUE ---\n",
    "    \"city of manchester stadium\": \"etihad\",\n",
    "    \"falmer stadium\": \"amex\",\n",
    "    \"dean court\": \"vitality\",\n",
    "    \"london stadium\": \"london stadium\",\n",
    "    \"tottenham hotspur stadium\": \"tottenham\",\n",
    "    \"brentford community stadium\": \"brentford\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 4. MATCHING LOGIC\n",
    "# ==========================================\n",
    "def get_match(row):\n",
    "    target_stad = row['norm_stad']\n",
    "    target_team = row['norm_team']\n",
    "    target_country = row['norm_country']\n",
    "    \n",
    "    candidates = [d for d in details_list if d['norm_country'] == target_country]\n",
    "    if not candidates: \n",
    "        candidates = details_list\n",
    "\n",
    "    # 1. Exact Stadium\n",
    "    for d in candidates:\n",
    "        if d['norm_stad'] == target_stad: \n",
    "            return d\n",
    "\n",
    "    # 2. Manual Map\n",
    "    if target_stad in manual_map:\n",
    "        key = manual_map[target_stad]\n",
    "        for d in candidates:\n",
    "            if key in d['norm_stad'] or key in d.get('clean_url', ''): \n",
    "                return d\n",
    "\n",
    "    # 3. Team in URL\n",
    "    if len(target_team) > 3:\n",
    "        for d in candidates:\n",
    "            if target_team in d.get('clean_url', ''): \n",
    "                return d\n",
    "\n",
    "    # 4. Team in Text\n",
    "    if len(target_team) > 4:\n",
    "        for d in candidates:\n",
    "            if target_team in d.get('search_text', ''): \n",
    "                return d\n",
    "\n",
    "    # 5. Fuzzy Match\n",
    "    all_stads = [d['norm_stad'] for d in candidates]\n",
    "    matches = difflib.get_close_matches(target_stad, all_stads, n=1, cutoff=0.55)\n",
    "    if matches:\n",
    "        best = matches[0]\n",
    "        for d in candidates:\n",
    "            if d['norm_stad'] == best: \n",
    "                return d\n",
    "\n",
    "    return None\n",
    "\n",
    "# ==========================================\n",
    "# 5. EXECUTE JOIN (LEFT JOIN - keep ALL df_coords rows)\n",
    "# ==========================================\n",
    "print(\"Joining...\")\n",
    "enriched = []\n",
    "matched_count = 0\n",
    "missing_count = 0\n",
    "\n",
    "for idx, row in df_coords.iterrows():\n",
    "    match = get_match(row)\n",
    "    \n",
    "    # Always create a row - LEFT JOIN behavior (keeps ALL df_coords rows)\n",
    "    new_row = {\n",
    "        'League': row['League'],\n",
    "        'Country': row['Country'],\n",
    "        'Team': row['Team'],\n",
    "        'Stadium': row['Stadium'],\n",
    "        'Latitude': row['Latitude'],\n",
    "        'Longitude': row['Longitude'],\n",
    "        'Directions': match.get('Directions') if match else None,\n",
    "        'Food_and_Stay': match.get('Food_and_Stay') if match else None,\n",
    "        'Ticket_Info': match.get('Ticket_Info') if match else None\n",
    "    }\n",
    "    enriched.append(new_row)\n",
    "    \n",
    "    if match:\n",
    "        matched_count += 1\n",
    "    else:\n",
    "        missing_count += 1\n",
    "\n",
    "df_final_stadiums = pd.DataFrame(enriched)\n",
    "\n",
    "# ==========================================\n",
    "# 6. OUTPUT\n",
    "# ==========================================\n",
    "print(f\"Total: {len(df_final_stadiums)} | Matched: {matched_count} | Missing: {missing_count}\")\n",
    "\n",
    "\n",
    "save_path = \"/dbfs/FileStore/Stadium_LLM_Enrichment.csv\"\n",
    "df_final_stadiums.to_csv(save_path, index=False)\n",
    "print(f\"Saved successfully to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba6b1958-77fd-435f-883e-d2c9c205f5a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>League</th><th>Country</th><th>Team</th><th>Stadium</th><th>Latitude</th><th>Longitude</th><th>Directions</th><th>Food_and_Stay</th><th>Ticket_Info</th></tr></thead><tbody><tr><td>Premier League</td><td>England</td><td>Arsenal</td><td>Emirates Stadium</td><td>51.55667</td><td>-0.10611</td><td>The Emirates Stadium is located in the Islington area, toward the north of London at just over 2 miles from Kings Cross St Pancras railway station. There are multiple ways to reach the stadium by public transport. Theunderground(tube) is one option – the nearest tube station is Arsenal, which is on the Piccadilly line. Decent alternatives are stations Finsbury Park (Victoria and Piccadilly line) and Highbury & Islington (Victoria line and London overground). From both stations it is an approximate 10-minute walk to the stadium. On non-matchdays, Holloway Road station (Piccadilly line) is located closest, but will be closed pre-match and is exit-only after the match. Alternatively, one can catch atrainto Finsbury Park or Highbury & Islington main line stations. It is a 5 to 10-minute journey coming from Kings Cross station. During the week trains depart from Moorgate as well. Drayton Park rail station, closest to the stadium, closes on matchdays. Supporters are not advised to arrive by car on matchdays, and there is little parking available around the Emirates Stadium on non-matchdays. Address: Emirates Stadium, London N5 1BU</td><td>The Emirates Stadium is located in the recently regenerated and rather quiet Highbury area. There are a few pubs and cafés in the immediate surroundings of the stadium, which is mainly residential, and some options to eat and drink along Holloway Road and Highbury Park road. More nightlife can be found in the Islington area on Upper Street starting south of Highbury & Islington tube station – an approximate 15 to 20-minute walk from the stadium. There are no hotels right near the Emirates Stadium, but a fair few options further north on Seven Sisters Road near Finsbury Park, which is a 15-minute walk from the stadium. TheQueens HotelandBest Western Highburyget the best reviews and go for about £100 a night, whereas thePembury Hotel,Woodberry Down Hotel, andCentral Park Hotelare more basic options. Clickherefor all hotels near the Emirates Stadium. Of course, as there are various tube lines passing by the stadium, you can just as well choose a stadium in any part ofCentral London.</td><td>Tickets for Arsenal matches can be boughtonline, or by phone 0844 277 3625 (+44 207 649 9003 if calling from abroad). Arsenal is one of the clubs in the Premier League for which it is hardest to get tickets and one will often need an Arsenal membership to be able to acquire tickets. The most basic Red level membership currently costs £33.00 and with it tickets will generally be available in pre-sale. Arsenal matches fall into three pricing categories. Tickets for category C matches, the cheapest, start at £26.00 for most lower-tier seats and range up to £51.00 for a central upper-tier seat. Tickets for category A matches, the most expensive, range from £63.50 for most lower-tier seats to £126.00 for a central upper-tier seat. A further booking fee of about £2.00 applies. Tickets for members are a little bit cheaper.</td></tr><tr><td>Premier League</td><td>England</td><td>Aston Villa</td><td>Villa Park</td><td>52.509166666667</td><td>-1.8847222222222</td><td>Info not available</td><td>Villa Park is located in a typical English urban area. This means that there are a few pubs around as well as some easy eating options, though if you have more time on your hands, Birmingham’s city centre might be a better option. If you arrive by car, you could stop at theStar Cityshopping centre just off exit 6 of the M6. It has the typical food outlets you tend to find at a shopping centre as well as various entertainment options. The nightlife in Birmingham’s city centre is mostly located west and south of Birmingham New Street Station. There are few hotels in the immediate vicinity of the stadium. TheHoliday Inn Expresslocated across Star City shopping centre is probably closest, but is mostly convenient if you get in by car. You can about just walk to the stadium from there. Further toward the centre, there are aCampanile HotelandPremier Inn. They are affordable and get good reviews, but are again most of all convenient for those arriving by car. If travelling by public transport, it is likely best to find a hotel in Birmingham’s centre, and take a bus or train to the match. For all hotels near Villa Park clickhere. For all options in the city centre gohere.</td><td>Tickets for Aston Villa matches can be boughtonline, by phone +44 (0) 800 6120 970, or at the Villa Village store at Villa Park. Tickets can also be bought at the same store before the start of the match. Aston Villa only very occasionally sell out. Aston Villa have divided their home games in three pricing categories. Tickets for category A matches, the most expensive, range in price from £25.00 for a lower-tier seat at the North Stand to £45.00 for a central seat at one of the long sides. Tickets for category VV matches, the cheapest, range in price from £20.00 to £37.00.</td></tr><tr><td>Premier League</td><td>England</td><td>Bournemouth</td><td>Dean Court</td><td>50.73528</td><td>-1.83833</td><td>The Vitality Stadium is located in the north-east of Bournemouth at a little over 2 miles from The Square and the Bournemouth Pier in the town centre. The main railway station lies roughly halfway the town centre and the stadium. The walk from the mainrailstation to the stadium will take just under half an hour. The stadium furthermore lies at walking distance from Pokesdown station, which lies south-east of the stadium. If arriving by car, take the A338 towards Bournemouth and exit towards Boscombe. Take the second exit on the roundabout and follow King’s Park Drive to the stadium. There are signs that point to the stadium (or Dean Court) along the way. Address: Dean Court, Kings Park, Bournemouth BH7 7AF</td><td>The Vitality Stadium is located in a quiet residential neighbourhood, and apart from a local pub, there is therefore little in the immediate vicinity of the stadium in terms of eating and drinking, which is best done in and around Bournemouth’s town centre. There are neither any hotels directly near the Vitality Stadium, but plenty of options in Bournemouth’stown centre, or even closer in the nearby Boscombe area (which while regenerated, still has a somewhat negative reputation in terms of safety).</td><td>Tickets for Bournemouth games can be boughtonline, over the phone +44 (0) 344 576 1910, or in person at the ticket office at the Vitality Stadium or the BIC & Pavilion ticket office on Exeter Road right off The Square in Bournemouth’s town centre. Ticket prices range from £32.00 for a seat behind the goal to £45.00 for a central seat at the Main Stand. Bournemouth currently sell out every match in their first season in the Premier League and one generally needs to have accrued a certain number of loyalty points to be able to obtain tickets. Emailtickets@afcb.co.ukor call +44 (0) 344 576 1910 for more information.</td></tr><tr><td>Premier League</td><td>England</td><td>Brentford</td><td>Brentford Community Stadium</td><td>51.49083</td><td>-0.28861</td><td>Brentford Community Stadium is located in the west of London just north of the river Thames at about 6 miles from central London. There are multiple ways to travel to Brentford Community Stadium by public transport. The nearest station is Kew Bridge station, which is on the rail network. Trains depart from Waterloo station roughly every 20-30 minutes on the weekend. The journey takes about half an hour. Kew Bridge station is right next to the stadium. If you prefer the London Underground, get a District Line train to Gunnersbury, which can be boarded at any of various stop in Central London including Bank, Westminster, Victoria, and South Kensington. The journey takes max. 30 minutes and it is a further 15-minute walk to the stadium. Gunnersbury is also a station on the Overground network with trains running from Stratford in the east and Richmond in the south. It is particularly useful if coming from various places in North or East London. Finally, the stadium is also at walking distance from Acton Town underground station (app. 25 minutes), which is on the Piccadilly Line and runs through central London to Heathrow.</td><td>Info not available</td><td>Brentford tickets can be boughtonline, or at the ticket office at Brentford Community Stadium. Ticket prices depend on the game. Games are split between high-profile Cat A games and regular Cat B games. Tickets for Cat A games range in price from £40.00 to £50.00 and those in Cat B games from £35.00 to £45.00. Emailtickets@brentfordfc.comfor more information.</td></tr><tr><td>Premier League</td><td>England</td><td>Brighton & Hove Albion</td><td>Falmer Stadium</td><td>50.861822222222</td><td>-0.083277777777778</td><td>Info not available</td><td>The Amex is located outside of the city of Brighton, bordered by the University of Sussex campus, some residential housing and farmlands. There is little around in terms of eating and drinking, which is recommended to be done in pleasant Brighton. The are neither any hotels in the close vicinity of The Amex, but there is plenty of choice in Brighton on the seafront. Clickherefor an overview of hotels in Brighton.</td><td>Tickets for Brighton matches can be boughtonline, or at the Ticket Office at The Amex Stadium. Tickets are also sold at the stadium on the day of the match. Brighton often sell out though so booking in advance is recommended. Ticket prices depend on the opponent. Prices for category C matches, the cheapest, range from £30.00 for a seat behind the goal to £46.00 for a central seat at one of the sides. Prices for category A matches, the most expensive, start at £45.00 and range up to £65.00 for the most expensive seats.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Premier League",
         "England",
         "Arsenal",
         "Emirates Stadium",
         51.55667,
         -0.10611,
         "The Emirates Stadium is located in the Islington area, toward the north of London at just over 2 miles from Kings Cross St Pancras railway station. There are multiple ways to reach the stadium by public transport. Theunderground(tube) is one option – the nearest tube station is Arsenal, which is on the Piccadilly line. Decent alternatives are stations Finsbury Park (Victoria and Piccadilly line) and Highbury & Islington (Victoria line and London overground). From both stations it is an approximate 10-minute walk to the stadium. On non-matchdays, Holloway Road station (Piccadilly line) is located closest, but will be closed pre-match and is exit-only after the match. Alternatively, one can catch atrainto Finsbury Park or Highbury & Islington main line stations. It is a 5 to 10-minute journey coming from Kings Cross station. During the week trains depart from Moorgate as well. Drayton Park rail station, closest to the stadium, closes on matchdays. Supporters are not advised to arrive by car on matchdays, and there is little parking available around the Emirates Stadium on non-matchdays. Address: Emirates Stadium, London N5 1BU",
         "The Emirates Stadium is located in the recently regenerated and rather quiet Highbury area. There are a few pubs and cafés in the immediate surroundings of the stadium, which is mainly residential, and some options to eat and drink along Holloway Road and Highbury Park road. More nightlife can be found in the Islington area on Upper Street starting south of Highbury & Islington tube station – an approximate 15 to 20-minute walk from the stadium. There are no hotels right near the Emirates Stadium, but a fair few options further north on Seven Sisters Road near Finsbury Park, which is a 15-minute walk from the stadium. TheQueens HotelandBest Western Highburyget the best reviews and go for about £100 a night, whereas thePembury Hotel,Woodberry Down Hotel, andCentral Park Hotelare more basic options. Clickherefor all hotels near the Emirates Stadium. Of course, as there are various tube lines passing by the stadium, you can just as well choose a stadium in any part ofCentral London.",
         "Tickets for Arsenal matches can be boughtonline, or by phone 0844 277 3625 (+44 207 649 9003 if calling from abroad). Arsenal is one of the clubs in the Premier League for which it is hardest to get tickets and one will often need an Arsenal membership to be able to acquire tickets. The most basic Red level membership currently costs £33.00 and with it tickets will generally be available in pre-sale. Arsenal matches fall into three pricing categories. Tickets for category C matches, the cheapest, start at £26.00 for most lower-tier seats and range up to £51.00 for a central upper-tier seat. Tickets for category A matches, the most expensive, range from £63.50 for most lower-tier seats to £126.00 for a central upper-tier seat. A further booking fee of about £2.00 applies. Tickets for members are a little bit cheaper."
        ],
        [
         "Premier League",
         "England",
         "Aston Villa",
         "Villa Park",
         52.509166666667,
         -1.8847222222222,
         "Info not available",
         "Villa Park is located in a typical English urban area. This means that there are a few pubs around as well as some easy eating options, though if you have more time on your hands, Birmingham’s city centre might be a better option. If you arrive by car, you could stop at theStar Cityshopping centre just off exit 6 of the M6. It has the typical food outlets you tend to find at a shopping centre as well as various entertainment options. The nightlife in Birmingham’s city centre is mostly located west and south of Birmingham New Street Station. There are few hotels in the immediate vicinity of the stadium. TheHoliday Inn Expresslocated across Star City shopping centre is probably closest, but is mostly convenient if you get in by car. You can about just walk to the stadium from there. Further toward the centre, there are aCampanile HotelandPremier Inn. They are affordable and get good reviews, but are again most of all convenient for those arriving by car. If travelling by public transport, it is likely best to find a hotel in Birmingham’s centre, and take a bus or train to the match. For all hotels near Villa Park clickhere. For all options in the city centre gohere.",
         "Tickets for Aston Villa matches can be boughtonline, by phone +44 (0) 800 6120 970, or at the Villa Village store at Villa Park. Tickets can also be bought at the same store before the start of the match. Aston Villa only very occasionally sell out. Aston Villa have divided their home games in three pricing categories. Tickets for category A matches, the most expensive, range in price from £25.00 for a lower-tier seat at the North Stand to £45.00 for a central seat at one of the long sides. Tickets for category VV matches, the cheapest, range in price from £20.00 to £37.00."
        ],
        [
         "Premier League",
         "England",
         "Bournemouth",
         "Dean Court",
         50.73528,
         -1.83833,
         "The Vitality Stadium is located in the north-east of Bournemouth at a little over 2 miles from The Square and the Bournemouth Pier in the town centre. The main railway station lies roughly halfway the town centre and the stadium. The walk from the mainrailstation to the stadium will take just under half an hour. The stadium furthermore lies at walking distance from Pokesdown station, which lies south-east of the stadium. If arriving by car, take the A338 towards Bournemouth and exit towards Boscombe. Take the second exit on the roundabout and follow King’s Park Drive to the stadium. There are signs that point to the stadium (or Dean Court) along the way. Address: Dean Court, Kings Park, Bournemouth BH7 7AF",
         "The Vitality Stadium is located in a quiet residential neighbourhood, and apart from a local pub, there is therefore little in the immediate vicinity of the stadium in terms of eating and drinking, which is best done in and around Bournemouth’s town centre. There are neither any hotels directly near the Vitality Stadium, but plenty of options in Bournemouth’stown centre, or even closer in the nearby Boscombe area (which while regenerated, still has a somewhat negative reputation in terms of safety).",
         "Tickets for Bournemouth games can be boughtonline, over the phone +44 (0) 344 576 1910, or in person at the ticket office at the Vitality Stadium or the BIC & Pavilion ticket office on Exeter Road right off The Square in Bournemouth’s town centre. Ticket prices range from £32.00 for a seat behind the goal to £45.00 for a central seat at the Main Stand. Bournemouth currently sell out every match in their first season in the Premier League and one generally needs to have accrued a certain number of loyalty points to be able to obtain tickets. Emailtickets@afcb.co.ukor call +44 (0) 344 576 1910 for more information."
        ],
        [
         "Premier League",
         "England",
         "Brentford",
         "Brentford Community Stadium",
         51.49083,
         -0.28861,
         "Brentford Community Stadium is located in the west of London just north of the river Thames at about 6 miles from central London. There are multiple ways to travel to Brentford Community Stadium by public transport. The nearest station is Kew Bridge station, which is on the rail network. Trains depart from Waterloo station roughly every 20-30 minutes on the weekend. The journey takes about half an hour. Kew Bridge station is right next to the stadium. If you prefer the London Underground, get a District Line train to Gunnersbury, which can be boarded at any of various stop in Central London including Bank, Westminster, Victoria, and South Kensington. The journey takes max. 30 minutes and it is a further 15-minute walk to the stadium. Gunnersbury is also a station on the Overground network with trains running from Stratford in the east and Richmond in the south. It is particularly useful if coming from various places in North or East London. Finally, the stadium is also at walking distance from Acton Town underground station (app. 25 minutes), which is on the Piccadilly Line and runs through central London to Heathrow.",
         "Info not available",
         "Brentford tickets can be boughtonline, or at the ticket office at Brentford Community Stadium. Ticket prices depend on the game. Games are split between high-profile Cat A games and regular Cat B games. Tickets for Cat A games range in price from £40.00 to £50.00 and those in Cat B games from £35.00 to £45.00. Emailtickets@brentfordfc.comfor more information."
        ],
        [
         "Premier League",
         "England",
         "Brighton & Hove Albion",
         "Falmer Stadium",
         50.861822222222,
         -0.083277777777778,
         "Info not available",
         "The Amex is located outside of the city of Brighton, bordered by the University of Sussex campus, some residential housing and farmlands. There is little around in terms of eating and drinking, which is recommended to be done in pleasant Brighton. The are neither any hotels in the close vicinity of The Amex, but there is plenty of choice in Brighton on the seafront. Clickherefor an overview of hotels in Brighton.",
         "Tickets for Brighton matches can be boughtonline, or at the Ticket Office at The Amex Stadium. Tickets are also sold at the stadium on the day of the match. Brighton often sell out though so booking in advance is recommended. Ticket prices depend on the opponent. Prices for category C matches, the cheapest, range from £30.00 for a seat behind the goal to £46.00 for a central seat at one of the sides. Prices for category A matches, the most expensive, start at £45.00 and range up to £65.00 for the most expensive seats."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "League",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Team",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Stadium",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Directions",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Food_and_Stay",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Ticket_Info",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_final_stadiums.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38c7c59-df6a-47cc-a2fc-f273e1c324cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDCC5 C. Football Match Schedule Ingestion (Web Scraping & APIs)\n",
    "- **Source**: football-data.co.uk (15 Domestic Leagues) & Wikipedia (UEFA Competitions).\n",
    "- **Goal**: To build a structured, unified table of historical and upcoming football matches (Dates, Teams, Leagues) that serves as the primary temporal filter for the recommendation engine.\n",
    "- **Method**: The pipeline utilizes pd.read_csv to ingest structured historical data and BeautifulSoup to scrape unstructured HTML fixtures. It normalizes disparate date formats and team names into a standardized Delta table (football_matches_final) for downstream processing.\n",
    "- **Domestic Leagues:** We ingest season-specific CSV feeds from *FixtureDownload.com*—spanning both the 2025/26 and 2026/27 campaigns—for 16 major competitions, including the \"Big 5\" (EPL, La Liga, etc.) and top tiers in the Netherlands, Portugal, Turkey, and Eastern Europe.\n",
    "- **Champions League:** A targeted `BeautifulSoup` scraper parses Wikipedia to extract upcoming matches for both the 2025/26 Knockout Phase and the start of the 2026/27 League Phase.\n",
    "- **Integration:** The pipeline strictly filters for 2026 dates, injects country metadata, normalizes timestamps to `YYYY-MM-DD`, and updates the **Spark Table** using schema-overwrite mode to ensure clean data persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99b4ee19-a0f4-4073-bf12-5b49bbe86086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n--- Step 1: Fetching Domestic Data (Football-Data.co.uk) ---\n   [INFO] Historical/Played matches processed. Total chunks: 45\n   [WARN] Could not fetch upcoming fixtures file: 'Div'\n\n--- Step 2: Scraping European Competitions (Wikipedia) ---\n   [OK] Processed CL Group 23/24       - Found 96 matches\n   [OK] Processed CL Knockout 23/24    - Found 29 matches\n   [OK] Processed CL League 24/25      - Found 144 matches\n   [OK] Processed CL Knockout 24/25    - Found 45 matches\n   [OK] Processed EL Group 23/24       - Found 96 matches\n   [OK] Processed EL Knockout 23/24    - Found 45 matches\n   [OK] Processed EL League 24/25      - Found 144 matches\n   [OK] Processed EL Knockout 24/25    - Found 45 matches\n\n--- Step 3: Consolidating Data ---\n   Total Matches Found: 14224\n\n   [SUCCESS] Data saved to table 'football_matches_final'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import urllib3\n",
    "import warnings\n",
    "\n",
    "# ==========================================\n",
    "# 0. CONFIGURATION & SETUP\n",
    "# ==========================================\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define Start Date (Adjust as needed)\n",
    "START_DATE = datetime(2023, 8, 1)  \n",
    "\n",
    "all_matches = []\n",
    "\n",
    "# Proxy Configuration (User Provided)\n",
    "PASSWORD = os.getenv('BRIGHTDATA_PASSWORD', 'YOUR_PASSWORD_HERE')\n",
    "BASE_USERNAME = os.getenv('BRIGHTDATA_USER', 'YOUR_ZONE_USERNAME_HERE') \n",
    "HOST = 'brd.superproxy.io'\n",
    "PORT = '33335'\n",
    "country_code = \"hu\" \n",
    "session_id = random.randint(1, 1000000)\n",
    "FINAL_USERNAME = f\"{BASE_USERNAME}-country-{country_code}-session-{session_id}\"\n",
    "\n",
    "PROXIES = {\n",
    "    'http': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}', \n",
    "    'https': f'http://{FINAL_USERNAME}:{PASSWORD}@{HOST}:{PORT}'\n",
    "}\n",
    "\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "                  'Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# PART 1: DOMESTIC LEAGUES (Source: Football-Data.co.uk)\n",
    "# ==========================================\n",
    "print(\"\\n--- Step 1: Fetching Domestic Data (Football-Data.co.uk) ---\")\n",
    "\n",
    "# Mapping League Names to Football-Data.co.uk codes\n",
    "# Note: 'football-data' covers major leagues deeply. Minor leagues are often in separate 'new' files.\n",
    "league_map = {\n",
    "    \"Premier League\": \"E0\",\n",
    "    \"Championship\": \"E1\",\n",
    "    \"La Liga\": \"SP1\",\n",
    "    \"Segunda Division\": \"SP2\",\n",
    "    \"Bundesliga\": \"D1\",\n",
    "    \"2. Bundesliga\": \"D2\",\n",
    "    \"Serie A\": \"I1\",\n",
    "    \"Serie B\": \"I2\",\n",
    "    \"Ligue 1\": \"F1\",\n",
    "    \"Ligue 2\": \"F2\",\n",
    "    \"Eredivisie\": \"N1\",\n",
    "    \"Belgian Pro League\": \"B1\",\n",
    "    \"Primeira Liga\": \"P1\",\n",
    "    \"Super Lig\": \"T1\",\n",
    "    \"Super League Greece\": \"G1\"\n",
    "}\n",
    "\n",
    "# Generate Season Strings for URLs (e.g., 2023 -> '2324')\n",
    "# We scan a few years back to ensure we get the requested history\n",
    "years = [2022, 2023, 2024, 2025] \n",
    "season_codes = []\n",
    "for y in years:\n",
    "    suffix = (y + 1) % 100\n",
    "    code = f\"{y % 100:02d}{suffix:02d}\" # e.g., 2324\n",
    "    season_codes.append(code)\n",
    "\n",
    "base_url_template = \"https://www.football-data.co.uk/mmz4281/{}/{}.csv\"\n",
    "\n",
    "for league_name, code in league_map.items():\n",
    "    for season in season_codes:\n",
    "        url = base_url_template.format(season, code)\n",
    "        try:\n",
    "            # Note: Verify=False is risky but kept per your config.\n",
    "            response = requests.get(url, headers=HEADERS, proxies=PROXIES, verify=False, timeout=20)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                try:\n",
    "                    pdf = pd.read_csv(StringIO(response.text))\n",
    "                except:\n",
    "                    # Fallback for common encoding issues in older CSVs\n",
    "                    pdf = pd.read_csv(StringIO(response.text), encoding='latin1')\n",
    "\n",
    "                # Normalize Columns to match your schema\n",
    "                if 'Date' in pdf.columns and 'HomeTeam' in pdf.columns:\n",
    "                    # Date parsing (football-data uses dd/mm/yy or dd/mm/yyyy)\n",
    "                    pdf['DT_Obj'] = pd.to_datetime(pdf['Date'], dayfirst=True, errors='coerce')\n",
    "                    pdf = pdf.dropna(subset=['DT_Obj']) # Drop rows with bad dates\n",
    "                    \n",
    "                    pdf['Date'] = pdf['DT_Obj'].dt.strftime('%Y-%m-%d')\n",
    "                    \n",
    "                    # Time is often present, but if missing default to 00:00\n",
    "                    if 'Time' in pdf.columns:\n",
    "                        pdf['Time'] = pdf['Time'].fillna('00:00').astype(str)\n",
    "                    else:\n",
    "                        pdf['Time'] = '00:00'\n",
    "\n",
    "                    # Select & Rename\n",
    "                    subset = pdf[['Date', 'Time', 'HomeTeam', 'AwayTeam', 'DT_Obj']].copy()\n",
    "                    subset['League'] = league_name\n",
    "                    \n",
    "                    # Filter by Date\n",
    "                    subset = subset[subset['DT_Obj'] >= START_DATE]\n",
    "                    subset = subset.drop(columns=['DT_Obj'])\n",
    "\n",
    "                    if not subset.empty:\n",
    "                        all_matches.append(subset)\n",
    "                        # print(f\"   -> Fetched {league_name} ({season})\")\n",
    "        except Exception as e:\n",
    "            # 404 is expected for future seasons that don't exist yet\n",
    "            continue\n",
    "\n",
    "print(f\"   [INFO] Historical/Played matches processed. Total chunks: {len(all_matches)}\")\n",
    "\n",
    "# --- PART 1.5: FETCH UPCOMING FIXTURES (Next 1-2 Weeks) ---\n",
    "# Football-Data provides a specific file for upcoming unplayed matches\n",
    "try:\n",
    "    url_fixtures = \"https://www.football-data.co.uk/fixtures.csv\"\n",
    "    resp_fix = requests.get(url_fixtures, headers=HEADERS, proxies=PROXIES, verify=False, timeout=20)\n",
    "    if resp_fix.status_code == 200:\n",
    "        pdf_fix = pd.read_csv(StringIO(resp_fix.text), encoding='latin1')\n",
    "        \n",
    "        # In this file, 'Div' is the league code. We map it back to names.\n",
    "        inv_map = {v: k for k, v in league_map.items()}\n",
    "        pdf_fix['League'] = pdf_fix['Div'].map(inv_map)\n",
    "        pdf_fix = pdf_fix.dropna(subset=['League']) # Keep only leagues we track\n",
    "        \n",
    "        pdf_fix['DT_Obj'] = pd.to_datetime(pdf_fix['Date'], dayfirst=True, errors='coerce')\n",
    "        pdf_fix['Date'] = pdf_fix['DT_Obj'].dt.strftime('%Y-%m-%d')\n",
    "        if 'Time' in pdf_fix.columns:\n",
    "            pdf_fix['Time'] = pdf_fix['Time'].fillna('00:00')\n",
    "        else:\n",
    "            pdf_fix['Time'] = '00:00'\n",
    "            \n",
    "        subset_fix = pdf_fix[['Date', 'Time', 'HomeTeam', 'AwayTeam', 'League']].copy()\n",
    "        \n",
    "        # Only future dates\n",
    "        subset_fix = subset_fix[pd.to_datetime(subset_fix['Date']) >= datetime.now()]\n",
    "        \n",
    "        if not subset_fix.empty:\n",
    "            all_matches.append(subset_fix)\n",
    "            print(f\"   [INFO] Fetched {len(subset_fix)} upcoming fixtures from main feed.\")\n",
    "except Exception as e:\n",
    "    print(f\"   [WARN] Could not fetch upcoming fixtures file: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# PART 2: EUROPEAN COMPETITIONS (Wikipedia)\n",
    "# ==========================================\n",
    "print(\"\\n--- Step 2: Scraping European Competitions (Wikipedia) ---\")\n",
    "\n",
    "wiki_config = [\n",
    "    # Champions League\n",
    "    (\"https://en.wikipedia.org/wiki/2023%E2%80%9324_UEFA_Champions_League_group_stage\", \"CL Group 23/24\"),\n",
    "    (\"https://en.wikipedia.org/wiki/2023%E2%80%9324_UEFA_Champions_League_knockout_phase\", \"CL Knockout 23/24\"),\n",
    "    (\"https://en.wikipedia.org/wiki/2024%E2%80%9325_UEFA_Champions_League_league_phase\", \"CL League 24/25\"),\n",
    "    (\"https://en.wikipedia.org/wiki/2024%E2%80%9325_UEFA_Champions_League_knockout_phase\", \"CL Knockout 24/25\"),\n",
    "    # Europa League\n",
    "    (\"https://en.wikipedia.org/wiki/2023%E2%80%9324_UEFA_Europa_League_group_stage\", \"EL Group 23/24\"),\n",
    "    (\"https://en.wikipedia.org/wiki/2023%E2%80%9324_UEFA_Europa_League_knockout_phase\", \"EL Knockout 23/24\"),\n",
    "    (\"https://en.wikipedia.org/wiki/2024%E2%80%9325_UEFA_Europa_League_league_phase\", \"EL League 24/25\"),\n",
    "    (\"https://en.wikipedia.org/wiki/2024%E2%80%9325_UEFA_Europa_League_knockout_phase\", \"EL Knockout 24/25\")\n",
    "]\n",
    "\n",
    "for url, label in wiki_config:\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, proxies=PROXIES, verify=False, timeout=30)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        match_boxes = soup.find_all('div', class_='footballbox')\n",
    "        count = 0\n",
    "\n",
    "        for match in match_boxes: \n",
    "            try:\n",
    "                # Robust extraction\n",
    "                home_tag = match.find(class_='fhome') or match.find('th', class_='fhome')\n",
    "                away_tag = match.find(class_='faway') or match.find('th', class_='faway')\n",
    "                \n",
    "                if not home_tag or not away_tag: continue\n",
    "                \n",
    "                home = home_tag.get_text(strip=True)\n",
    "                away = away_tag.get_text(strip=True)\n",
    "                \n",
    "                date_div = match.find(class_='fdate')\n",
    "                time_div = match.find(class_='ftime')\n",
    "                raw_date = date_div.get_text(strip=True) if date_div else \"\"\n",
    "                match_time = time_div.get_text(strip=True) if time_div else \"00:00\"\n",
    "\n",
    "                # Date Parsing (Handles \"25 October 2023\")\n",
    "                match_date_match = re.search(r'(\\d{1,2}\\s+\\w+\\s+\\d{4})', raw_date)\n",
    "                if match_date_match:\n",
    "                    clean_date_str = match_date_match.group(1)\n",
    "                    try:\n",
    "                        dt_obj = datetime.strptime(clean_date_str, \"%d %B %Y\")\n",
    "                    except ValueError:\n",
    "                        continue # Skip bad dates\n",
    "                    \n",
    "                    if dt_obj >= START_DATE:\n",
    "                        fmt_date = dt_obj.strftime(\"%Y-%m-%d\")\n",
    "                        league_label = \"Champions League\" if \"Champions\" in label else \"Europa League\"\n",
    "                        \n",
    "                        all_matches.append(pd.DataFrame([{\n",
    "                            \"Date\": fmt_date, \n",
    "                            \"Time\": match_time,\n",
    "                            \"HomeTeam\": home, \n",
    "                            \"AwayTeam\": away, \n",
    "                            \"League\": league_label,\n",
    "                        }]))\n",
    "                        count += 1\n",
    "            except Exception as row_err: \n",
    "                continue\n",
    "        print(f\"   [OK] Processed {label:<20} - Found {count} matches\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   [ERROR] Scrape failed for {label}: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# PART 3: CONSOLIDATE & SAVE\n",
    "# ==========================================\n",
    "print(\"\\n--- Step 3: Consolidating Data ---\")\n",
    "\n",
    "if all_matches:\n",
    "    full_schedule = pd.concat(all_matches, ignore_index=True)\n",
    "    \n",
    "    # Clean up whitespace\n",
    "    full_schedule['HomeTeam'] = full_schedule['HomeTeam'].str.strip()\n",
    "    full_schedule['AwayTeam'] = full_schedule['AwayTeam'].str.strip()\n",
    "    \n",
    "    # Sort and Drop Duplicates\n",
    "    full_schedule = full_schedule.sort_values(by=['Date', 'Time'])\n",
    "    full_schedule = full_schedule.drop_duplicates(subset=['Date', 'HomeTeam', 'AwayTeam'])\n",
    "    \n",
    "    print(f\"   Total Matches Found: {len(full_schedule)}\")\n",
    "\n",
    "    \n",
    "    # --- DATABRICKS / SPARK SAVE ---\n",
    "    # Only runs if 'spark' session is available (Databricks env)\n",
    "    try:\n",
    "        if 'spark' in globals():\n",
    "            df_schedule = spark.createDataFrame(full_schedule)\n",
    "            df_schedule.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"football_matches_final\")\n",
    "            print(\"\\n   [SUCCESS] Data saved to table 'football_matches_final'\")\n",
    "        else:\n",
    "            print(\"\\n   [NOTE] Spark not detected. Skipping table save.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n   [ERROR] Could not save to Spark: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n   [WARNING] No matches found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b38772d-2660-420c-9cd4-907a3bd81ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Date</th><th>Time</th><th>HomeTeam</th><th>AwayTeam</th><th>League</th></tr></thead><tbody><tr><td>2023-08-04</td><td>17:30</td><td>Hertha</td><td>Wehen</td><td>2. Bundesliga</td></tr><tr><td>2023-08-04</td><td>17:30</td><td>Paderborn</td><td>Osnabruck</td><td>2. Bundesliga</td></tr><tr><td>2023-08-04</td><td>19:45</td><td>Standard</td><td>St. Gilloise</td><td>Belgian Pro League</td></tr><tr><td>2023-08-04</td><td>20:00</td><td>Sheffield Weds</td><td>Southampton</td><td>Championship</td></tr><tr><td>2023-08-05</td><td>12:00</td><td>Elversberg</td><td>Hansa Rostock</td><td>2. Bundesliga</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2023-08-04",
         "17:30",
         "Hertha",
         "Wehen",
         "2. Bundesliga"
        ],
        [
         "2023-08-04",
         "17:30",
         "Paderborn",
         "Osnabruck",
         "2. Bundesliga"
        ],
        [
         "2023-08-04",
         "19:45",
         "Standard",
         "St. Gilloise",
         "Belgian Pro League"
        ],
        [
         "2023-08-04",
         "20:00",
         "Sheffield Weds",
         "Southampton",
         "Championship"
        ],
        [
         "2023-08-05",
         "12:00",
         "Elversberg",
         "Hansa Rostock",
         "2. Bundesliga"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "HomeTeam",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "AwayTeam",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "League",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_schedule.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7bacb8e-3b0a-45b4-a24f-860a66220e1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDD0ED. Data Enrichment & Integration\n",
    "\n",
    "This step merges the **Match Schedules** and **Stadium Locations** into a single master table.\n",
    "\n",
    "* **The Challenge:** Discrepancies in team names between sources (e.g., *\"Man United\"* vs. *\"Manchester United\"*).\n",
    "* **The Solution:** We implement a **normalization dictionary** to map CSV names to their Wikipedia counterparts. A smart join key (`coalesce`) ensures matches are linked correctly even when naming varies.\n",
    "* **The Result:**  An inner join produces `euro_matches_enriched`, a clean dataset containing the **Who, When, and Where** for every match, ready for geospatial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c86e9675-f5f6-4025-aeb4-21e1c2f184d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching teams...\nMerging...\nFinal Filtered Count: 10264\nSaving final data to /dbfs/FileStore/Match_Schedule_All_Leagues.csv...\nSaved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "import unicodedata\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Helper to ensure standard Pandas DataFrames\n",
    "# ---------------------------------------------------------\n",
    "def ensure_local_pandas(df):\n",
    "    if hasattr(df, 'toPandas'): return df.toPandas()\n",
    "    elif hasattr(df, 'to_pandas'): return df.to_pandas()\n",
    "    return df\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Load Data\n",
    "# ---------------------------------------------------------\n",
    "pdf_games = ensure_local_pandas(df_schedule).copy()\n",
    "pdf_stadiums = ensure_local_pandas(df_final_stadiums).copy()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Setup Logic\n",
    "# ---------------------------------------------------------\n",
    "def normalize_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    return text.lower().strip()\n",
    "\n",
    "aliases = {\n",
    "    'Man Utd': 'Manchester United', 'Man City': 'Manchester City',\n",
    "    'Spurs': 'Tottenham Hotspur', 'Wolves': 'Wolverhampton Wanderers',\n",
    "    'Leeds': 'Leeds United', 'Nottm Forest': 'Nottingham Forest',\n",
    "    'Sheff Utd': 'Sheffield United', 'Stade Rennais FC': 'Rennes',\n",
    "    'RC Celta': 'Celta Vigo', 'Cadiz': 'Cádiz CF',\n",
    "    'Paris SG': 'Paris Saint-Germain', 'PSG': 'Paris Saint-Germain',\n",
    "    'Sporting CP': 'Sporting', 'Inter': 'Internazionale', \n",
    "    'Milan': 'AC Milan', 'Athletic Club': 'Athletic Bilbao', \n",
    "    'Atletico': 'Atlético Madrid'\n",
    "}\n",
    "\n",
    "pdf_stadiums = pdf_stadiums.drop_duplicates(subset=['Team'])\n",
    "stadium_teams_by_league = {}\n",
    "for league, group in pdf_stadiums.groupby('League'):\n",
    "    stadium_teams_by_league[league] = [(normalize_text(t), t) for t in group['Team'].unique()]\n",
    "all_stadium_teams = [(normalize_text(t), t) for t in pdf_stadiums['Team'].unique()]\n",
    "\n",
    "def find_best_match(row):\n",
    "    team_name = row.get('HomeTeam')\n",
    "    league = row.get('League')\n",
    "    if pd.isna(team_name): return None\n",
    "    \n",
    "    if team_name in aliases:\n",
    "        target = aliases[team_name]\n",
    "        norm_target = normalize_text(target)\n",
    "        for n, o in all_stadium_teams:\n",
    "            if n == norm_target: return o\n",
    "        return target \n",
    "\n",
    "    norm_name = normalize_text(team_name)\n",
    "    candidates = stadium_teams_by_league.get(league, [])\n",
    "    if league == 'Europa League' or not candidates: candidates = all_stadium_teams\n",
    "        \n",
    "    for n, o in candidates:\n",
    "        if n == norm_name: return o\n",
    "    for n, o in candidates:\n",
    "        if (n in norm_name and len(n) > 3) or (norm_name in n and len(norm_name) > 3): return o\n",
    "            \n",
    "    cand_names = [c[0] for c in candidates]\n",
    "    matches = difflib.get_close_matches(norm_name, cand_names, n=1, cutoff=0.6)\n",
    "    if matches:\n",
    "        for n, o in candidates:\n",
    "            if n == matches[0]: return o\n",
    "            \n",
    "    if league != 'Europa League':\n",
    "        for n, o in all_stadium_teams:\n",
    "            if n == norm_name: return o\n",
    "        matches = difflib.get_close_matches(norm_name, [c[0] for c in all_stadium_teams], n=1, cutoff=0.75)\n",
    "        if matches:\n",
    "            for n, o in all_stadium_teams:\n",
    "                if n == matches[0]: return o\n",
    "    return None\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Apply, Merge, and Filter\n",
    "# ---------------------------------------------------------\n",
    "print(\"Matching teams...\")\n",
    "pdf_games['StadiumTeam'] = pdf_games.apply(find_best_match, axis=1)\n",
    "\n",
    "print(\"Merging...\")\n",
    "df_merged = pd.merge(\n",
    "    pdf_games, \n",
    "    pdf_stadiums, \n",
    "    left_on='StadiumTeam', \n",
    "    right_on='Team', \n",
    "    how='left', \n",
    "    suffixes=('', '_stadium')\n",
    ")\n",
    "\n",
    "# --- FILTERING STEP ---\n",
    "# Drop rows where 'Stadium' is NaN (null)\n",
    "df_final = df_merged[df_merged['Stadium'].notna()]\n",
    "\n",
    "# Cleanup columns\n",
    "cols_to_drop = ['StadiumTeam', 'Team', 'League_stadium']\n",
    "df_final.drop(columns=[c for c in cols_to_drop if c in df_final.columns], inplace=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Header Standardization & Output\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# 2. Define the mapping from your CURRENT columns to the TARGET headers\n",
    "# (Adjust the left-side keys if your stadium/schedule source names differ slightly)\n",
    "rename_map = {\n",
    "    'HomeTeam': 'home_team',\n",
    "    'AwayTeam': 'away_team',\n",
    "    'League': 'league_name',\n",
    "    'Stadium': 'stadium_name',\n",
    "    # Handle variations in stadium source data\n",
    "    'Lat': 'latitude',       'Latitude': 'latitude',\n",
    "    'Lon': 'longitude',      'Longitude': 'longitude'\n",
    "}\n",
    "\n",
    "# 3. Apply renaming\n",
    "df_final = df_final.rename(columns=rename_map)\n",
    "\n",
    "# 4. Define the strict final schema requested\n",
    "target_headers = [\n",
    "    \"Date\",\n",
    "    \"Time\",\n",
    "    \"Country\", \n",
    "    \"home_team\",\n",
    "    \"away_team\",\n",
    "    \"league_name\",\n",
    "    \"stadium_name\",\n",
    "    \"latitude\",\n",
    "    \"longitude\"\n",
    "]\n",
    "\n",
    "# 5. Filter and Reorder columns\n",
    "# This ensures only the requested columns exist in the final output\n",
    "# using reindex to avoid errors if a column (like 'Country') is temporarily missing\n",
    "df_final = df_final.reindex(columns=target_headers)\n",
    "\n",
    "print(f\"Final Filtered Count: {len(df_final)}\")\n",
    "\n",
    "# Use the full path explicitly\n",
    "save_path = \"/dbfs/FileStore/Match_Schedule_All_Leagues.csv\"\n",
    "\n",
    "print(f\"Saving final data to {save_path}...\")\n",
    "df_final.to_csv(save_path, index=False)\n",
    "print(\"Saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e4e3054-ab5d-4389-92ad-242675ace7d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Date</th><th>Time</th><th>Country</th><th>home_team</th><th>away_team</th><th>league_name</th><th>stadium_name</th><th>latitude</th><th>longitude</th></tr></thead><tbody><tr><td>2023-08-04</td><td>19:45</td><td>Belgium</td><td>Standard</td><td>St. Gilloise</td><td>Belgian Pro League</td><td>Stade Maurice Dufrasne</td><td>50.61</td><td>5.54333</td></tr><tr><td>2023-08-05</td><td>12:00</td><td>Germany</td><td>Holstein Kiel</td><td>Greuther Furth</td><td>2. Bundesliga</td><td>Holstein-Stadion</td><td>54.34917</td><td>10.12361</td></tr><tr><td>2023-08-05</td><td>12:00</td><td>Germany</td><td>St Pauli</td><td>Fortuna Dusseldorf</td><td>2. Bundesliga</td><td>Millerntor-Stadion</td><td>53.554583</td><td>9.967667</td></tr><tr><td>2023-08-05</td><td>14:00</td><td>France</td><td>St Etienne</td><td>Grenoble</td><td>Ligue 2</td><td>Stade Geoffroy Guichard</td><td>45.46083</td><td>4.39028</td></tr><tr><td>2023-08-05</td><td>15:00</td><td>England</td><td>Bristol City</td><td>Preston</td><td>Championship</td><td>King Power Stadium</td><td>52.620277777778</td><td>-1.1422222222222</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2023-08-04",
         "19:45",
         "Belgium",
         "Standard",
         "St. Gilloise",
         "Belgian Pro League",
         "Stade Maurice Dufrasne",
         50.61,
         5.54333
        ],
        [
         "2023-08-05",
         "12:00",
         "Germany",
         "Holstein Kiel",
         "Greuther Furth",
         "2. Bundesliga",
         "Holstein-Stadion",
         54.34917,
         10.12361
        ],
        [
         "2023-08-05",
         "12:00",
         "Germany",
         "St Pauli",
         "Fortuna Dusseldorf",
         "2. Bundesliga",
         "Millerntor-Stadion",
         53.554583,
         9.967667
        ],
        [
         "2023-08-05",
         "14:00",
         "France",
         "St Etienne",
         "Grenoble",
         "Ligue 2",
         "Stade Geoffroy Guichard",
         45.46083,
         4.39028
        ],
        [
         "2023-08-05",
         "15:00",
         "England",
         "Bristol City",
         "Preston",
         "Championship",
         "King Power Stadium",
         52.620277777778,
         -1.1422222222222
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Time",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "home_team",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "away_team",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "league_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "stadium_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_final.head(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Scraping Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
